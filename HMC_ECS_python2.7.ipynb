{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path: /Users/miaocai/anaconda3/envs/p27/bin/python\n",
      "Python version: 2.7.16 |Anaconda, Inc.| (default, Sep 24 2019, 16:55:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "pandas version: 0.24.2\n",
      "numpy version: 1.16.5\n",
      "numdifftools version: 0.7.3\n"
     ]
    }
   ],
   "source": [
    "# Need python 2.7, and downgrade numpy to version 1.16.1\n",
    "from __future__ import division\n",
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "import numdifftools as nd # need to degrade to 0.7.3\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#os.chdir('D:\\\\Dropbox\\\\Aim2\\\\@HMCECS')\n",
    "os.chdir('/Users/miaocai/Dropbox/Aim2/@HMCECS')\n",
    "from functions import*\n",
    "\n",
    "print \"Python path: \" + sys.executable\n",
    "print \"Python version: \" + sys.version\n",
    "print \"pandas version: \" + pd.__version__\n",
    "print \"numpy version: \" + np.__version__\n",
    "print \"numdifftools version: \" + nd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 8136.740375\n",
      "         Iterations: 10\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 20\n",
      "         Hessian evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "npar = 10\n",
    "np.random.seed(1234)   \n",
    "dataFile = 'data'+str(npar)+ 'Par'\n",
    "\n",
    "#------------------------------------------------#   \n",
    "data_ip = np.loadtxt(dataFile +'.txt')\n",
    "#beta_true = np.loadtxt('betaTrue.txt') \n",
    "\n",
    "n= len(data_ip)\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# define prior\n",
    "priorInfo = getPrior('gaussian',npar,scale = 5) #Assume N(0,5^2) for all parameters\n",
    "\n",
    "# initialize\n",
    "betaMP = minimize(minuslogpost, np.zeros(npar), args= (data_ip[:,0],data_ip[:,1:],5),method='Newton-CG', jac=minusDerPost,hess = minusHessPost,options={'disp': True})\n",
    "beta_bar = betaMP['x']\n",
    "\n",
    "# mass matrix M. default is identity matrix\n",
    "pCov = np.identity(npar)\n",
    "beta = np.random.multivariate_normal(beta_bar,1e-4*np.linalg.inv(pCov),1)[0]\n",
    "\n",
    "# There are quite a numeber of tuning parameters needed for HMCECS\n",
    "# They need to be specified as input for the main function\n",
    "\n",
    "\n",
    "burnin = 600\n",
    "samples = 1000\n",
    "logFile = 'test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Arguments for adaptation.\n",
    "\n",
    "Note that when we set $M=I$ then epsilon is small and I don't spend too much time in the first few iterations. This is obtained by by changing $\\epsilon*L$ everytime I think $M$ changes a lot. Note that M is updated every time the reference for control variate is updated. Not necessary when M is fixed or you have the optimal M. The setting are arbitrary - just make sure that we have enough iterations with the desired $\\epsilon*L$ and the value in the last 2 elements of trajLength is your desired $\\epsilon*L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start HMCECS\n",
      "10.0% ; nsteps now is: 53; mean acc_u is: 0.9992850660615227 and acc_theta: 0.8034502827004498\n",
      "20.0% ; nsteps now is: 1; mean acc_u is: 0.9993829219198929 and acc_theta: 0.8131396897911942\n",
      "30.0% ; nsteps now is: 1; mean acc_u is: 0.999260888697361 and acc_theta: 0.8110148422373797\n",
      "40.0% ; nsteps now is: 2; mean acc_u is: 0.999300383529427 and acc_theta: 0.810443697980374\n",
      "50.0% ; nsteps now is: 2; mean acc_u is: 0.9992506158939023 and acc_theta: 0.8186485592542576\n",
      "60.0% ; nsteps now is: 2; mean acc_u is: 0.9992605857402249 and acc_theta: 0.8204967572892894\n",
      "70.0% ; nsteps now is: 2; mean acc_u is: 0.9992324964534041 and acc_theta: 0.821307954463641\n",
      "80.0% ; nsteps now is: 2; mean acc_u is: 0.9992519590660415 and acc_theta: 0.8206981512050598\n",
      "90.0% ; nsteps now is: 2; mean acc_u is: 0.9992503824450196 and acc_theta: 0.8200630448602634\n"
     ]
    }
   ],
   "source": [
    "phaseStart = np.array([   1,100,200, burnin]) #if M is fixed : np.array([   1,burnin])\n",
    "trajLength =np.array([ 0.1,1.2,1.2 ,1.2 ]) # if M is fixed : np.array([ 1 ,1 ])\n",
    "\n",
    "adaptInfoSub = {'adapt':True,'alpha': 0.80,'gamma': 0.05, 'kappa': 0.75,'t0':10,'updateM':True,\n",
    "'phaseStartPt': phaseStart,'tol': 1e-8,'diagM':False,'maxEps':1,'cov':'full','updateRef':True}\n",
    "\n",
    "# some additional information for the hmc step\n",
    "hmcInfo = {'eps':0.001,'trajLength':trajLength,'pCov': pCov,'maxSteps':300}\n",
    "\n",
    "# choose either the perturbed or signed (exact) version\n",
    "algorithm = 'perturbed'\n",
    "\n",
    "if (algorithm == 'perturbed'):\n",
    "    # some additional settings for subsampling part: \n",
    "    # subsize: subsample size. Note that in practice you should estimate the variance of the log-likelihood estimator and use that information to set the subsample size\n",
    "    # biasCorrect: (True/False) for perturbed version only, whether to add the bias correction to likelihood and gradient evaluation\n",
    "    # updateFreq: how often the reference theta* is updated (eg: every 200 iterations)\n",
    "    # updateU: (True/False) whether to run the first step of HMCECS or not\n",
    "    # rho: correlation in the blocking of subsample. rho = 0.99 is equivalent to update 1% of the subsample only\n",
    "    # order: the order of the Taylor expansion \n",
    "    subsampleApprox = {'subsize': int(n*0.01),'biasCorrect':True,'updateFreq':200,'updateU':True,'rho' : 0.99,'order':2}\n",
    "    output = hmc_within_gibbs(data_ip[:,0],data_ip[:,1:], beta, beta_bar,burnin,samples,hmcInfo,priorInfo,subsampleApprox,adaptInfoSub,logFile)\n",
    "else:\n",
    "    # some additional settings for subsampling part: \n",
    "    # subsize: subsample \"chunk\" size. Please refer to paper\n",
    "    lambda_ = 100\n",
    "    dhat_mean = 0\n",
    "    a_ = dhat_mean-lambda_\n",
    "    mb = 30#\n",
    "    # note that signed HMCECS are implemented with 2nd order Taylor expansion control variate only\n",
    "    subsampleExact = {'subsize': mb,'lambda':lambda_,'a':a_,'biasCorrect':True,'updateFreq':200,'updateU':True,'rho' : 0.99,'order':2}\n",
    "    output = hmc_ecs_Exact(data_ip[:,0],data_ip[:,1:], beta, beta_bar,burnin,samples,hmcInfo,priorInfo,subsampleExact,adaptInfoSub,logFile)\n",
    "\n",
    "# note that the output is an dictionary\n",
    "np.save('HMCECS1.npy', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test- full data HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% 5.0% 10.0% 10.0% ; nsteps now is: 77; mean acc is: 0.8018815292905994\n",
      "15.0% 20.0% 20.0% ; nsteps now is: 1; mean acc is: 0.8126977330564487\n",
      "25.0% 30.0% 30.0% ; nsteps now is: 2; mean acc is: 0.8097083024389788\n",
      "35.0% 40.0% 40.0% ; nsteps now is: 2; mean acc is: 0.8042796366174259\n",
      "45.0% 50.0% 50.0% ; nsteps now is: 2; mean acc is: 0.8061098747987989\n",
      "55.0% 60.0% 60.0% ; nsteps now is: 2; mean acc is: 0.8089194641963462\n",
      "65.0% 70.0% 70.0% ; nsteps now is: 2; mean acc is: 0.8155605406468716\n",
      "75.0% 80.0% 80.0% ; nsteps now is: 2; mean acc is: 0.8189510645924308\n",
      "85.0% 90.0% 90.0% ; nsteps now is: 2; mean acc is: 0.8197950518162478\n",
      "95.0% "
     ]
    }
   ],
   "source": [
    "adaptInfoHMC = {'adapt':True,'alpha': 0.80,'gamma': 0.05, 'kappa': 0.75,'t0':10,'updateM':True,\n",
    "'phaseStartPt': phaseStart,'tol': 1e-8, 'diagM':False,'maxEps':1,'updateFreq':200}\n",
    "\n",
    "logFile ='test.txt'\n",
    "\n",
    "hmcFull = hmc(data_ip[:,0],data_ip[:,1:], beta,burnin,samples,0.001,trajLength,300,pCov,priorInfo,adaptInfoHMC,logFile)\n",
    "\n",
    "np.save('HMCFit.npy',hmcFull)\n",
    "\n",
    "\n",
    "#for p in xrange(npar):\n",
    "#    plt.figure(p)\n",
    "#    plt.plot(hmcFull['par']['theta'][:,p],label = 'hmc')\n",
    "#    plt.plot(output['par']['theta'][:,p],label = 'hmcecs')\n",
    "#    plt.legend()\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# SGHMC\n",
    "runSGHMC = False\n",
    "if (runSGHMC):\n",
    "    ControlVariate = 2\n",
    "    m = int(n*0.01)\n",
    "    epsilon = 0.2\n",
    "    sghmcPar = {'C':np.identity(npar),'V':np.zeros([npar,npar]),'subsize':m}\n",
    "    adaptSGHMC = {'updateFreq':200, 'updateM':False,'diagM':False,'adapt':False,'phaseStartPt': [1]}\n",
    "    \n",
    "    sghmc_1= sghmcMat(data_ip[:,0],data_ip[:,1:], beta,beta_bar,burnin,samples,epsilon,[1.2],hmcFull['M'],sghmcPar,priorInfo,adaptSGHMC,ControlVariate,logFile,saveTempOutput=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p27",
   "language": "python",
   "name": "p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
