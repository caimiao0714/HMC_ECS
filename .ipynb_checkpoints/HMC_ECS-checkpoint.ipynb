{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import halfcauchy\n",
    "from scipy.stats import invgamma\n",
    "from scipy.linalg import sqrtm\n",
    "import scipy.optimize\n",
    "import random\n",
    "import numpy.random as npr\n",
    "import copy\n",
    "import time\n",
    "import scipy.stats as sps\n",
    "#import mpmath as mp\n",
    "import scipy.special\n",
    "import os\n",
    "import numdifftools as nd\n",
    "from scipy.special import polygamma, gammaln "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1523)\n",
    "#precision = 150\n",
    "#mp.mp.prec += precision\n",
    "def loglike_ind(y,x,theta):\n",
    "    \n",
    "    \"\"\"this function evaluate the individual log likelihood at individual level\n",
    "     input is whole data set\n",
    "    \"\"\"\n",
    "    \n",
    "    npar = np.shape(x)[1]\n",
    "    tmp = x.dot(theta[:npar])\n",
    "    if np.any(tmp > 700):\n",
    "        tmp[np.where(tmp>700)]=700\n",
    "    \n",
    "    out = (y.T)*tmp - np.log1p(np.exp(tmp))\n",
    "    \n",
    "    if(np.isnan(out).any()==True):\n",
    "        out[np.where(np.isnan(out))] = np.log(1e-100)\n",
    "    return out  \n",
    "    \n",
    "#---------------------------------------------------#\n",
    "def loglike_all(y,x,theta):\n",
    "    \"\"\" \n",
    "    loglikelihood of whole data set\n",
    "    \"\"\"\n",
    "    npar = np.shape(x)[1]\n",
    "    ll_ind = loglike_ind(y,x,theta[:npar])\n",
    "    out = np.sum(ll_ind)\n",
    "    return out\n",
    "  \n",
    "#-----------------------------------------------------------#\n",
    "def hessianll(x,theta):\n",
    "    \"\"\"function that evaluate the second derivative of the likelihood at a value of the data , for 1 data point\"\"\"\n",
    "    \n",
    "    npar = len(x) # number of real parameter\n",
    "    out = np.zeros([len(theta),len(theta)])\n",
    "    out[:npar,:npar] = -np.exp(np.dot(x,theta[:npar]))/(1+np.exp(np.dot(x,theta[:npar])))**2*np.outer(x,x)\n",
    "    return out\n",
    "    \n",
    "def hessianll2(x,theta):\n",
    "    \"\"\"function that evaluate the second derivative of the (individual) likelihood at a value of the data \"\"\"\n",
    "    npar = np.int(np.shape(x)[1])\n",
    "    \n",
    "    tmp = -1/(np.exp(0.5*np.dot(x,theta[:npar]))+np.exp(-0.5*np.dot(x,theta[:npar])))**2\n",
    "    out = np.zeros([len(x),len(theta),len(theta)])\n",
    "    out[:,:npar,:npar] = np.array(map(np.multiply,x[:,:,None]*x[:,None,:],tmp))\n",
    "    \n",
    "    return out\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "def sumHessian(x,theta):\n",
    "    n = len(x)\n",
    "    H = 0\n",
    "    for i in range(0,n):\n",
    "        H = H + hessianll(x[i],theta)\n",
    "    return H\n",
    "    \n",
    "#-----------------------------------------------------------#\n",
    "def hessianPrior(theta,family,par1,par2):\n",
    "    \"\"\"function that evaluate the second derivative of the prior at a value of the data \"\"\"\n",
    "\n",
    "    if(family== 'gaussian'):\n",
    "        out = -np.linalg.inv(par2)\n",
    "        \n",
    "    else:\n",
    "        print (\"prior not defined !\")\n",
    "        out = np.nan\n",
    "    return out\n",
    "#---------------------------------------------------#\n",
    "def devll_ind(y,x,theta):\n",
    "    \n",
    "    \"\"\"\n",
    "    function that evaluate the first derivative of the log likelihood at a value of the data\n",
    "    for individual\n",
    "    \"\"\"\n",
    "    \n",
    "    #npar = np.shape(data)[1]-1L\n",
    "    npar = len(x)\n",
    "    tmp = np.dot(x,theta[:npar])\n",
    "    if (tmp < -700):\n",
    "       tmp=-700\n",
    "    out = np.zeros(len(theta))\n",
    "    out[:npar] = y*x - x*1/(1+np.exp(-tmp))\n",
    "    return out  \n",
    "#-------------------------------------------#\n",
    "def devll(y,x,theta):\n",
    "    \"\"\" for a set of observations\n",
    "    \"\"\"\n",
    "    npar = np.shape(x)[1] #number of 'real' parameters- betas\n",
    "    tmp = np.dot(x,theta[:npar])\n",
    "    if (np.any(tmp < -700)==True):\n",
    "       tmp[np.where(tmp<-700)]=-700\n",
    "    tmp = 1/(1+np.exp(-tmp)) \n",
    "    out = np.zeros([len(y),npar])\n",
    "    out[:,:npar] = np.multiply(x.T,y-tmp).T   \n",
    "    #out = y*x - np.multiply(x.T,tmp).T\n",
    "    return out\n",
    "#--------------------------------------------------#\n",
    "def sumDev(y,x,theta):\n",
    "    n = len(y)\n",
    "    D = 0\n",
    "    for i in range(0,n):\n",
    "        D = D+   devll_ind(y[i],x[i],theta)  \n",
    "    return D\n",
    "#---------------------------------------------------#    \n",
    "def dprior(theta,family,par1,par2):\n",
    "    \"\"\"\n",
    "    log prior \n",
    "    \n",
    "    for a gaussian prior, par1 is mean, par2 is covariance matrix\n",
    "    \"\"\"\n",
    "    if family =='gaussian':\n",
    "        out = -0.5*np.dot((theta-par1),np.linalg.solve(par2,(theta-par1)))\n",
    "        #out = np.log(max(1e-300,multivariate_normal.pdf(theta,par1,par2)))\n",
    "    else:\n",
    "        print ('prior not defined')\n",
    "        out = np.nan\n",
    "    return out\n",
    "    \n",
    "#------------------------------------------------------#\n",
    "def gradPrior(theta,prior,npar,priorPar1 = 0, priorPar2  =0):\n",
    "    \n",
    "    if prior =='gaussian':\n",
    "        gradPrior = - np.linalg.solve(priorPar2,theta-priorPar1)\n",
    "    else:\n",
    "        print ('prior not defined')\n",
    "        gradPrior = np.nan\n",
    "    return gradPrior\n",
    "#---------------------------------------------------#\n",
    "def gradU(y,x,theta,prior='uniform',priorPar1=0,priorPar2=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    function that evaluate the gradient of minus the log posterior \n",
    "    \"\"\"\n",
    "    npar = np.shape(x)[1]\n",
    "    const = 1/(1+np.exp(-np.dot(x,theta[:npar])))\n",
    "    dev_ind = y.reshape(-1,1)*x - const.reshape(-1,1)*x\n",
    "    gradll= np.zeros(len(theta))\n",
    "    gradll[:npar] = -np.sum(dev_ind,axis =0) #minus gradient of log likelihood\n",
    "    gPrior = gradPrior(theta,prior,npar,priorPar1,priorPar2)\n",
    "    out = gradll  - gPrior\n",
    "    return out\n",
    "\n",
    "#----------------------------------------------------#\n",
    "def potential(y,x,theta,par1,par2,family):\n",
    "    \"\"\" potential energy\"\"\"\n",
    "    U = -(loglike_all(y,x,theta)+dprior(theta,family,par1,par2))\n",
    "    return U\n",
    "    \n",
    "#----------------------------------------------------------#\n",
    "def kinetic(p,M):\n",
    "    # technically just minus the log of multivariate normal density with mean 0 and covariance M, without the normalizing constant\n",
    "    # may be numpy library is faster but just use the formular first\n",
    "   \n",
    "    K = 0.5*p.dot(np.linalg.solve(M,p))\n",
    "    return K\n",
    "    \n",
    "#----------------------------------------------------------#\n",
    "def hmc(y,x, theta,burnin,samples,eps,trajLength,maxSteps,M,priorArgs,adaptArgs,logFile,saveTempOutput=False):\n",
    "    \"\"\" IMPLEMENTATION OF HMC WITH ADAPTIVE WARMUP\n",
    "        M to be updated using the output from the previous iterations\n",
    "        eps to be updated continously during burnin\n",
    "        \n",
    "    \"\"\"\n",
    "    # eps is stepsize (starting value, to be update if burnin>0)\n",
    "    # L is number of steps (fix)\n",
    "    # M is covariance matrix of p (to be update if burnin > 0)\n",
    "    \n",
    "    # burnin = 0 implies no update at all\n",
    "    \n",
    "    #n = len(data)\n",
    "    niter = burnin + samples\n",
    "    npar = len(theta)\n",
    "    nbetas = np.shape(x)[1]\n",
    "    theta_keep = np.zeros([niter,npar])\n",
    "    theta_propose = np.zeros([niter,npar])\n",
    "    acc_rate = np.zeros(niter)\n",
    "    L_keep = np.zeros(niter)\n",
    "    L = int(trajLength[0]/eps)\n",
    "    timePerIter = np.zeros(niter)\n",
    "    Hdiff = np.zeros(niter)\n",
    "    # arguments for prior\n",
    "    pfamily = priorArgs['family']\n",
    "    priorPar1 = priorArgs['par1']\n",
    "    priorPar2 = priorArgs['par2']\n",
    "    \n",
    "    meanp = np.zeros(len(theta))\n",
    "    #-------------------------------#\n",
    "    updateFreq = adaptArgs['updateFreq']\n",
    "    alpha = adaptArgs['alpha'] #desired acceptance rate\n",
    "    gamma =adaptArgs['gamma']\n",
    "    kappa = adaptArgs['kappa']\n",
    "    updateM = adaptArgs['updateM']\n",
    "    t0 = adaptArgs['t0']\n",
    "    Hbar = 0 #Hbar is a sumstat ~ different between the desired acceptance rate and the mean acceptance rate upto time t\n",
    "    mu = np.log(10*eps)\n",
    "    logEps = np.log(eps)\n",
    "    logEpsBar = 0\n",
    "    #-----------------------------------#\n",
    "    #\n",
    "    if(adaptArgs['adapt']==True and burnin>0):\n",
    "        eps_keep =np.zeros(niter)\n",
    "        eps_keep[0] = eps\n",
    "        diagM = adaptArgs['diagM']\n",
    "        phaseStartPt = adaptArgs['phaseStartPt']\n",
    "        if(len(phaseStartPt) != len(trajLength)):\n",
    "            print('phaseEndPt must have same length as trajLength')\n",
    "            \n",
    "        phase = 0\n",
    "    else:\n",
    "        eps_keep = eps\n",
    "    #-------------------------------#\n",
    "    try:\n",
    "        for i in range(0,niter):\n",
    "            progress = i*100/niter\n",
    "            if np.mod(progress,5)==0:\n",
    "                print(str(progress)+ \"% \",end= \"\")\n",
    "            if (np.mod(progress,10)==0 and i>0):\n",
    "                msg = str(progress) + \"% ; nsteps now is: \" + str(L) + \"; mean acc is: \" + str(np.mean(acc_rate[:i]))\n",
    "                print(msg)\n",
    "                lf = open(logFile,\"a\")\n",
    "                lf.write(msg+ '\\n')\n",
    "                lf.close()\n",
    "                if(saveTempOutput):\n",
    "                    part = int(progress*0.1)\n",
    "                    temp = {'par':theta_keep[:i],'eps':eps_keep,'M':M}\n",
    "                    np.save('output/temp'+ str(part) + '.npy',temp)\n",
    "                        \n",
    "            startT = time.time() \n",
    "            \n",
    "               \n",
    "            p = np.random.multivariate_normal(meanp,M,1)[0]\n",
    "            thetacurrent = theta\n",
    "            Hcurrent = -(loglike_all(y,x,theta[:nbetas])+dprior(theta,pfamily,priorPar1,priorPar2))+ kinetic(p,M)\n",
    "            \n",
    "            L_keep[i] = L\n",
    "            # move p by half a step\n",
    "            p = p-0.5*eps*gradU(y,x,theta,pfamily,priorPar1,priorPar2)\n",
    "            for s in range(0,L):\n",
    "                # move position\n",
    "                theta = theta+ eps*np.linalg.solve(M,p)\n",
    "                # move momentum\n",
    "                if s<(L-1):\n",
    "                    p = p - eps*gradU(y,x,theta,pfamily,priorPar1,priorPar2)\n",
    "                else:\n",
    "                    p = p - 0.5*eps*gradU(y,x,theta,pfamily,priorPar1,priorPar2)\n",
    "                \n",
    "            # negate p\n",
    "            p = -p\n",
    "            theta_propose[i] = theta\n",
    "            H = -(loglike_all(y,x,theta[:nbetas])+dprior(theta,pfamily,priorPar1,priorPar2))+ kinetic(p,M)\n",
    "        \n",
    "            \n",
    "            reject = False\n",
    "            Hdiff[i] = Hcurrent - H\n",
    "            accrate = np.exp(min([0,(Hcurrent-H)]))#\n",
    "            reject = (np.random.uniform(0,1,1)> accrate)\n",
    "            if reject==True:\n",
    "                theta = thetacurrent\n",
    "                H = Hcurrent\n",
    "            stopT = time.time()\n",
    "            timePerIter[i] = stopT- startT\n",
    "            \n",
    "            #------------------------------------------------#\n",
    "            # adjust eps and M if burnin > 0\n",
    "            # don't evaluate the time getting new eps for adaptive tunning as it's small\n",
    "            if(burnin >0):\n",
    "                t = i+ 1\n",
    "                if(adaptArgs['adapt']==True):\n",
    "                    if(updateM and np.mod(i+1,updateFreq)==0 ):\n",
    "                        startT = time.time()\n",
    "                        if(diagM ==True):\n",
    "                            var_theta = np.var(theta_keep[int(i/2):(i+1),:],axis = 0) #take half the iteration as the first iters might not be informative\n",
    "                            M= np.diag(1/var_theta)\n",
    "                        else:\n",
    "                            \n",
    "                            thetaRef = np.mean(theta_keep[int(0.5*i):i,:],axis =0)\n",
    "                            \n",
    "                            Hprior = hessianPrior(thetaRef,pfamily,priorPar1,priorPar2)\n",
    "                            M = -sumHessian(x, thetaRef) - Hprior\n",
    "                        stopT = time.time()\n",
    "                        timePerIter[i] = timePerIter[i] + stopT- startT  \n",
    "                    \n",
    "                    if(i< burnin):\n",
    "                        Hbar = (1-1/(t+t0))*Hbar + 1/(t+t0)*(alpha-accrate)\n",
    "                        logEps = mu - np.sqrt(t)/gamma*Hbar\n",
    "                        logEpsBar = t**(-kappa)*logEps + (1-t**(-kappa))*logEpsBar\n",
    "                                                                                                        \n",
    "                        if(phase < len(phaseStartPt)):\n",
    "                            if((i+1)==phaseStartPt[phase]):\n",
    "                                currentTrajLength = trajLength[phase]\n",
    "                                phase +=1 #next phase is phase 1\n",
    "                            # reset\n",
    "                            #if(phase < len(phaseStartPt)):\n",
    "                            #    mu = np.log(10*eps)\n",
    "                            #    logEps = np.log(eps)\n",
    "                            #    logEpsBar = 0\n",
    "                            #    Hbar = 0 \n",
    "                        eps = np.min([adaptArgs['maxEps'],np.exp(logEps),currentTrajLength])\n",
    "                        eps_keep[t] = eps\n",
    "                        L = min(maxSteps,int(round(currentTrajLength/eps,0)))   \n",
    "                        if (L==0):\n",
    "                            print('number of steps reaches 0!')\n",
    "                            L +=1     \n",
    "                        if(t==burnin) :\n",
    "                            # t == burnin\n",
    "                            eps = np.min([np.exp(logEpsBar),adaptArgs['maxEps'],currentTrajLength])\n",
    "                            eps_keep[t:] = eps\n",
    "                            L = min(maxSteps,int(round(trajLength[-1]/eps,0)))\n",
    "                            L_fix = max(1,L)\n",
    "                    \n",
    "                    else:\n",
    "                        L = L_fix\n",
    "                else:\n",
    "                    if t < burnin :\n",
    "                        L = int(round(trajLength[0]/eps,0))\n",
    "                    else:\n",
    "                        L = int(round(trajLength[1]/eps,0))\n",
    "                                                                \n",
    "                \n",
    "            theta_keep[i]= theta\n",
    "            acc_rate[i] = accrate\n",
    "    except Warning as w:\n",
    "        print (str(w))\n",
    "    except TypeError as e:\n",
    "        print('type error' + str(e))\n",
    "    except ValueError as e:\n",
    "        print('value error'+ str(e))\n",
    "    except IndexError as e:\n",
    "       print('Index error'+ str(e))\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print('Bye')\n",
    "    lf = open(logFile,\"a\")\n",
    "    lf.write('Run completed successfully')\n",
    "    lf.close()\n",
    "    \n",
    "    finalpar = {'theta':theta_keep}\n",
    "    currentSet = {'theta':theta,'iter':i}\n",
    "    return {'par':finalpar,'acc': acc_rate,'eps':eps_keep,'nsteps':L_keep,'M':M,'Hbar':Hbar,'runTime':timePerIter,\n",
    "    'Hdiff': Hdiff,'current':currentSet,'proposal':theta_propose,'args':adaptArgs}\n",
    "      \n",
    "#--------------------------------------------------------#\n",
    "def proxy_ind(y,x,theta,thetaref,d1,d2=0,order = 2):\n",
    "    \n",
    "    llref = loglike_ind(y,x,thetaref)\n",
    "    if(order==0):\n",
    "        q = llref\n",
    "    else:\n",
    "        q = llref + np.dot(d1,(theta-thetaref))# \n",
    "        if (order ==2):\n",
    "            q = q + 0.5*(theta-thetaref).dot(d2).dot(theta-thetaref)\n",
    "    return q\n",
    "#---------------------------------------------------------#\n",
    "def proxy_ind1stOrder(y,x,theta,thetaref,d1):\n",
    "    \n",
    "    llref = loglike_ind(y,x,thetaref)\n",
    "    q = llref + np.dot(d1,(theta-thetaref)) \n",
    "    return q\n",
    "    \n",
    "#--------------------------------------------------------#\n",
    "def diff_ind(y_u,x_u,theta,thetaref,d1_u,d2_u=0,order = 2):\n",
    "    \n",
    "    # u is the vector of index of obs included\n",
    "    #evaluate d_i = l_i- q_i\n",
    "    lltrue = loglike_ind(y_u,x_u,theta)\n",
    "    \n",
    "    proxy = proxy_ind(y_u,x_u,theta,thetaref,d1_u,d2_u,order)\n",
    "    diff = np.array(lltrue) - np.array(proxy)\n",
    "    return diff\n",
    "    \n",
    "#--------------------------------------------------------#\n",
    "def proxy_sum(theta,thetaref,llref,g,H=0,order=2):\n",
    "    if(order ==0):\n",
    "        proxySum =llref\n",
    "    else:\n",
    "        proxySum = llref + g.dot(theta-thetaref) #\n",
    "        if (order==2):\n",
    "            proxySum = proxySum + 0.5*(theta-thetaref).dot(H).dot(theta-thetaref)\n",
    "    return proxySum\n",
    "\n",
    "#--------------------------------------------------------#\n",
    "def loglike_est(theta,thetaref,llref,g,H,diff_i,n,order = 2):\n",
    "    \"\"\" log likelihood estimate. Require computing d_i beforehand \"\"\"\n",
    "    m = len(diff_i)\n",
    "    sumProxy = proxy_sum(theta,thetaref,llref,g,H,order)\n",
    "    out = sumProxy + n/m*np.sum(diff_i)\n",
    "    \n",
    "    return out\n",
    "\n",
    "#---------------------------------------------------------#\n",
    "def sumGradU_est(theta,thetaRef,dev1_sum,dev2_sum=0,order =2):\n",
    "    \"\"\" SUM OF ESTIMATED GRADIENT FOR ALL N \"\"\"\n",
    "    if(order==0):\n",
    "        sumgrad = 0\n",
    "    else:\n",
    "        sumgrad = dev1_sum #\n",
    "        if(order==2):\n",
    "            sumgrad = sumgrad + dev2_sum.dot(theta-thetaRef)\n",
    "    return sumgrad\n",
    "#------------------------------------------------------------#\n",
    "def init_u(mb,n,algorithm,lambda_=50,rho = 0.99):\n",
    "    \"\"\"\n",
    "    Note: n is the population size, m is the size of the subsample, G is the number of blocks\n",
    "    \"\"\"\n",
    "    G = np.round(1/(1-rho),0)\n",
    "    if algorithm =='Approx':\n",
    "        # Update one of the blocks:\n",
    "        uCurr = npr.randint(0, n, mb) \n",
    "        \n",
    "        # Divide the random variates into blocks\n",
    "        groupindicators = np.hstack((np.repeat(np.arange(G-1), mb/G), np.repeat(G-1, mb - len(np.repeat(np.arange(G-1), mb/G)))))\t\n",
    "    \n",
    "        return uCurr, groupindicators\n",
    "    elif algorithm == 'Exact':\n",
    "        \"\"\" Initialize u for the product poisson estimator\n",
    "            uCurr has fixed length(lambda)\n",
    "            each element of uCurr has a random length base on X_l ~ Poisson(1)\n",
    "            each component of each element of uCurr has fixed length m\n",
    "        \"\"\"\n",
    "        uCurr = [[npr.choice(np.arange(n),mb) for item in xrange(sps.poisson.rvs(1))] for item in xrange(lambda_)]\n",
    "        Gc = np.sum([len(item) for item in uCurr]) # total number of u's used. The cost is Gc*m\n",
    "        kappa = int(round(lambda_/G,0))\n",
    "        \n",
    "        return uCurr, Gc, kappa \n",
    "    else:\n",
    "        print('Invalid algorithm')\n",
    "\n",
    "\n",
    "def uProp_given_uCurr(mb, n, uCurr, algorithm, lambda_, groupindicators= 0,kappa = 1):\n",
    "    \"\"\"\n",
    "    Propoposes u given uCurr \n",
    "    \"\"\"\n",
    "    if algorithm =='Approx':\n",
    "    # Update one of the blocks:\n",
    "        G = max(groupindicators)+1\n",
    "        toUpdate = npr.randint(0, G, 1)[0]\n",
    "        uProp = copy.copy(uCurr)\n",
    "        update = (groupindicators == toUpdate)\n",
    "        uProp[update] = npr.randint(0, n, np.sum(update)) \n",
    "        \n",
    "        return uProp,np.where(update)\n",
    "    elif algorithm == 'Exact':\n",
    "        \"\"\" Choose one block of uCurr and update all the u there\"\"\"\n",
    "        uProp = copy.copy(uCurr)\n",
    "        \n",
    "        BlockToChange = npr.choice(lambda_, kappa, replace = False)\n",
    "        for b in BlockToChange:\n",
    "            uProp[b] = [npr.choice(np.arange(n),mb) for item in xrange(sps.poisson.rvs(1))]\n",
    "        Gp = np.sum([len(item) for item in uProp]) #cost at proposed is Gp*m\n",
    "        return uProp, Gp, BlockToChange\n",
    "        \n",
    "    else:\n",
    "        print('Invalid algorithm')\n",
    "#--------------------------------------------------------------#\n",
    "def component_xi(y_xi,x_xi,theta,thetaref,dev1_xi,dev2_xi,llref,a,lambda_,n):\n",
    "    \"\"\" use this to calculate one xi_l only \"\"\"\n",
    "    \n",
    "    # data is a list of matrix of subdata (length = Chi_l)\n",
    "    # something like data_subFull= [[data[subset] for subset in item] for item in u] which has length lambda\n",
    "    # then for each xi use data_subFull[l], which is of length xi, and is a list of matrices of size m*p\n",
    "    # similarly for dev1_xi and dev2_xi\n",
    "    Chi_l = len(y_xi)\n",
    "    diff_h = np.zeros(Chi_l)\n",
    "    if Chi_l ==0 :\n",
    "        xi_l = np.exp(1+a/lambda_)\n",
    "        sigma2_dhat = 0\n",
    "    else:\n",
    "        m = np.shape(x_xi[0])[0]\n",
    "        var_set = np.zeros(Chi_l)\n",
    "        for h in range(0,Chi_l):\n",
    "            diffs = diff_ind(y_xi[h],x_xi[h],theta,thetaref,dev1_xi[h],dev2_xi[h])\n",
    "            diff_h[h] =n/m*np.sum(diffs) #d_hat_m\n",
    "            \n",
    "           \n",
    "        xi_l = np.exp(1+a/lambda_)*np.prod((diff_h-a)/lambda_)   \n",
    "        sigma2_dhat = np.mean(var_set)        \n",
    "    return xi_l,sigma2_dhat\n",
    "\n",
    "#------------------------------------------------------------------------#s\n",
    "def sumStats(theta_keep):\n",
    "    mean = np.mean(theta_keep,axis = 0)\n",
    "    sd = np.std(theta_keep,axis = 0)\n",
    "    return{'mean': mean,'std':sd}\n",
    "    \n",
    "#--------------------------------------------------------------------------#\n",
    "def Var_abs_LogL_hat(m, lambda_, gamma, sum_trunc = 100):\n",
    "    \"\"\"\n",
    "    sum_trunc: number of terms to include before truncating the sum\n",
    "    \"\"\"\n",
    "    mean_pois = m*lambda_**2/(2*gamma)\n",
    "    #sum_trunc = sum_trunc*np.ones(mean_pois.shape).astype(int)\n",
    "    upper = np.int(np.max([sum_trunc, sps.poisson.ppf(0.99999999, mean_pois)])) # np.maximum.reduce([sum_trunc, sps.poisson.ppf(0.99999999, mean_pois)])\t\n",
    "    JPois = np.arange(upper)\n",
    "    nu2 = 0.25*(np.sum(polygamma(1, 0.5 + JPois)*sps.poisson.pmf(JPois, mean_pois)) + np.sum((polygamma(0, 0.5 + JPois) - np.sum(polygamma(0, 0.5 + JPois)*sps.poisson.pmf(JPois, mean_pois)))**2*sps.poisson.pmf(JPois, mean_pois)))\n",
    "    eta = np.log(np.sqrt(gamma/(m*lambda_**2))) + 0.5*(np.log(2) + np.sum(polygamma(0, 0.5 + JPois)*sps.poisson.pmf(JPois, mean_pois)))\n",
    "    \n",
    "    return lambda_*(nu2 + eta**2)\n",
    "      \n",
    "#-----------------------------------------------------------------------------#\n",
    "def dhat_block(y_u,x_u,theta,thetaref,d1,d2,n,gradient = False,order = 2):\n",
    "    # compute d_hat_m in block (h,l)\n",
    "\t# data_u is data of block h,l\n",
    "    m = len(x_u)\n",
    "    if (m>0):\n",
    "        \n",
    "        lltrue = loglike_all(y_u,x_u,theta)\n",
    "        llref = loglike_all(y_u,x_u,thetaref) # sum of l_i in sub-block h,l\n",
    "        if(order ==2):\n",
    "            dhat_m_hl = n/m*(lltrue - llref - np.dot(d1,(theta-thetaref)) - 0.5*(theta-thetaref).dot(d2).dot(theta-thetaref))\n",
    "        else:\n",
    "            if(order==1):\n",
    "                dhat_m_hl = n/m*(lltrue - llref - np.dot(d1,(theta-thetaref)))\n",
    "            else:\n",
    "                dhat_m_hl = n/m*(lltrue - llref)\n",
    "        #q = llref + np.dot(d1,(theta-thetaref)) + 0.5*(theta-thetaref).dot(d2).dot(theta-thetaref)\n",
    "        if(gradient):\n",
    "            dev1_component = np.sum(devll(y_u,x_u,theta),axis = 0)\n",
    "            grad_logdhat_m = dev1_component-d1  # note that this is the part of the gradient without the denominator\n",
    "            if(order ==2):\n",
    "                grad_logdhat_m = grad_logdhat_m - d2.dot(theta-thetaref) \n",
    "            return grad_logdhat_m,dhat_m_hl    \n",
    "        else:\n",
    "            return dhat_m_hl\n",
    "    else:\n",
    "        dhat_m_hl = 0\n",
    "        if(gradient):\n",
    "            grad_logdhat_m = 0# note that this is the part of the gradient without the denominator\n",
    "            return grad_logdhat_m,dhat_m_hl  \n",
    "        else:\n",
    "            return dhat_m_hl\n",
    "        \n",
    "#---------------------------------------------------------------------------------#\n",
    "\n",
    "def loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaref,n,subsamplingDict,getLoglike = True,getGradient=True):\n",
    "    # data is a list of matrix of subdata (length = Chi_l)\n",
    "    # something like data_subFull= [[data[subset] for subset in item] for item in u] which has length lambda\n",
    "    # then for each xi use data_subFull[l], which is of length xi, and is a list of matrices of size m*p\n",
    "    # similarly for dev1_xi and dev2_xi\n",
    "    # output gradient of minus log-likelihood as well\n",
    "    a = subsamplingDict['a']\n",
    "    lambda_ = subsamplingDict['lambda']\n",
    "        \n",
    "    dhat_m = [[dhat_block(y_sub_item,x_sub_item,theta,thetaref,sub_item2,sub_item3,n,order = subsamplingDict['order']) for y_sub_item, x_sub_item, sub_item2,sub_item3 in zip(y_item,x_item,item2,item3)] \n",
    "    if (len(y_item)>0) else [] for y_item,x_item,item2,item3 in zip(y_sub,x_sub,subsamplingDict['dev1_sumComponent'],subsamplingDict['dev2_sumComponent'])]\n",
    "                \n",
    "    if(getLoglike):\n",
    "        component_xi = [(np.asarray(item)-a)/lambda_ if (len(item)>0) else [1] for item in dhat_m]\n",
    "        logprods = [np.log(np.abs(item))  for item in component_xi]\n",
    "        signL = np.prod([np.prod(np.sign(xi)) for xi  in component_xi])\n",
    "                # report log likelihood \n",
    "        l_hat = subsamplingDict['sumProxy'] + a + lambda_ +  np.sum([np.sum(item) for item in logprods]) #log(|Lhat|)\n",
    "                #        \n",
    "        #----------------------------#\n",
    "        # get variance\n",
    "        \"\"\" This is pretty costly to compute and not neccessary so I skipped it\"\"\"\n",
    "        #dhat = np.mean([np.mean(item) for item in dhat_m])\n",
    "        #lenItem = np.array([len(item) for item in dhat_m])\n",
    "        #nonEmpty = np.where(lenItem>1)[0][0]#[1:10]\n",
    "        \n",
    "        #newlist = [item for sublist in dhat_m for item in sublist]\n",
    "        #gamma =subsamplingDict['subsize']*np.var(newlist)\n",
    "        #sigma2_LL = Var_abs_LogL_hat(subsamplingDict['subsize'], lambda_, gamma, sum_trunc = 100)\n",
    "        sigma2_LL= 0\n",
    "    else:\n",
    "        l_hat = 0\n",
    "        signL = 1\n",
    "        sigma2_LL  = 0\n",
    "    #-------------------------------------------------------------------#\n",
    "    # calculating gradient\n",
    "    \n",
    "    if(getGradient):\n",
    "        \n",
    "        dev1_component = [[np.sum(devll(y_subset,x_subset,theta),axis = 0) for y_subset,x_subset in zip(y_item,x_item)] for y_item,x_item in zip(y_sub,x_sub)]\n",
    "        \n",
    "        sumGrad =  sumGradU_est(theta,thetaref,subsamplingDict['sumDev1'],subsamplingDict['sumDev2'],order = subsamplingDict['order']) # grad(q)\n",
    "        grad_logprods =  [np.sum([(sub_item1-sub_item2- sub_item3.dot(theta-thetaref))/(sub_item4-a) for sub_item1,sub_item2,sub_item3,sub_item4 in zip(item1,item2,item3,item4)],axis =0) \n",
    "        if (len(item1)>0) else np.zeros(len(theta)) \n",
    "        for item1,item2,item3,item4 in zip(dev1_component,subsamplingDict['dev1_sumComponent'],subsamplingDict['dev2_sumComponent'],dhat_m)]\n",
    " \n",
    "        grad_minusloglike = -(sumGrad + n/subsamplingDict['subsize']*np.sum(grad_logprods,axis = 0))\n",
    "    else:\n",
    "        grad_minusloglike = 0\n",
    "    \n",
    "    return grad_minusloglike,l_hat,signL,sigma2_LL\n",
    "        \n",
    "#-----------------------------------------------------------------------------#\n",
    "def minusloglike_estPoisson(theta,y,x,u,thetaref,n,subsamplingDict):\n",
    "    subsamplingDict['sumProxy'] = proxy_sum(theta,thetaref,subsamplingDict['llRef'],subsamplingDict['sumDev1'],subsamplingDict['sumDev2'])\n",
    "    a = subsamplingDict['a']\n",
    "    lambda_ = subsamplingDict['lambda']\n",
    "        \n",
    "    dhat_m = [[dhat_block(y[sub_item1],x[sub_item1],theta,thetaref,sub_item2,sub_item3,n,order = subsamplingDict['order']) for sub_item1,sub_item2,sub_item3 in zip(item1,item2,item3)] if (len(item1)>0) else [] for item1,item2,item3 in zip(u,subsamplingDict['dev1_sumComponent'],subsamplingDict['dev2_sumComponent'])]\n",
    "\n",
    "    component_xi = [(np.asarray(item)-a)/lambda_ if (len(item)>0) else [1] for item in dhat_m]\n",
    "    logprods = [np.log(np.abs(item))  for item in component_xi]\n",
    "   # signL = np.prod([np.prod(np.sign(xi)) for xi  in component_xi])\n",
    "            # report log likelihood \n",
    "    l_hat = subsamplingDict['sumProxy'] + a + lambda_ +  np.sum([np.sum(item) for item in logprods]) #log(|Lhat|)\n",
    "    return -l_hat \n",
    "\n",
    "gradminusLoglike=nd.Gradient(minusloglike_estPoisson)\n",
    "hessian_minusLoglike = nd.Hessian(minusloglike_estPoisson)\n",
    "hessian_minusLoglikeDiag = nd.Hessdiag(minusloglike_estPoisson)#\n",
    "#----------------------------------------------------------------------------#\n",
    "def hmc_ecs_Exact(y,x, theta, thetaRef,burnin,samples,hmcArgs,priorArgs,subsampleArgs,adaptArgs,logFile,saveTempOutput=False):\n",
    "    \"\"\" \n",
    "        Implement with adaptive eps. Fix trajectory length (L*eps)\n",
    "        \n",
    "        I haven't test 1st order exact hmcecs\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    niter = burnin + samples\n",
    "    npar = len(theta)\n",
    "    #---------------------------#\n",
    "    # arguments for prior\n",
    "    pfamily = priorArgs['family']\n",
    "    priorPar1 = priorArgs['par1']\n",
    "    priorPar2 = priorArgs['par2']\n",
    "    #---------------------------------#\n",
    "    # HMC argument\n",
    "    meanp = np.zeros(npar)\n",
    "    eps = hmcArgs['eps']\n",
    "    trajLength = hmcArgs['trajLength']\n",
    "    L = int(round(trajLength[0]/eps,0))\n",
    "    M = hmcArgs['pCov']\n",
    "    maxSteps = hmcArgs['maxSteps']\n",
    "    Mhalf = np.linalg.cholesky(M)\n",
    "    #--------------------------------------#\n",
    "    # subsampling arguments\n",
    "    m = subsampleArgs['subsize']\n",
    "    a_ = subsampleArgs['a']\n",
    "    lambda_ = subsampleArgs['lambda']\n",
    "    rho = subsampleArgs['rho']\n",
    "    nblocks = 1/(1-rho)\n",
    "    updateFreq = subsampleArgs['updateFreq']\n",
    "    updateU = subsampleArgs['updateU']\n",
    "    cvorder = subsampleArgs['order']\n",
    "    #-------------------------------------------#\n",
    "    # adapt arguments\n",
    "    updateM = adaptArgs['updateM']\n",
    "    \n",
    "    \n",
    "    if(adaptArgs['adapt']==True and (burnin >0)):\n",
    "        Hbar = 0 #Hbar is a sumstat ~ different between the desired acceptance rate and the mean acceptance rate upto time t\n",
    "        alpha = adaptArgs['alpha'] #desired acceptance rate\n",
    "        gamma =adaptArgs['gamma']\n",
    "        kappa = adaptArgs['kappa']\n",
    "        t0 = adaptArgs['t0']             \n",
    "        mu = np.log(10*eps)\n",
    "        logEps = np.log(eps)\n",
    "        logEpsBar = 0\n",
    "        eps_keep = np.zeros(niter)\n",
    "        \n",
    "       \n",
    "    else:\n",
    "        eps_keep = eps\n",
    "    phaseStartPt = adaptArgs['phaseStartPt']\n",
    "    if(len(phaseStartPt) != len(trajLength)):\n",
    "        print('phaseEndPt must have same length as trajLength')    \n",
    "    phase = 0\n",
    "    currentTrajLength = trajLength[phase]\n",
    "    phase = 1\n",
    "    #------------------------------------------------#\n",
    "    # allocate memory for outcome\n",
    "    theta_keep= np.zeros([niter,npar])\n",
    "    sigmaHat_keep  = np.zeros([niter,2])\n",
    "    acc_rate = np.zeros([niter,2])\n",
    "    L_keep = np.zeros(niter)\n",
    "    acc_prob = np.zeros([niter,2])\n",
    "    timePerIter= np.zeros([niter,2])\n",
    "    signL = np.zeros([niter,2])\n",
    "    lambda_use = np.zeros(niter)\n",
    "    #-----------------------------------------------#\n",
    "    # initialize\n",
    "    u_m, Gc, unitsPerBlock = init_u(m,n,'Exact',lambda_,rho)\n",
    "    u0 = copy.deepcopy(u_m)\n",
    "    \n",
    "    y_sub = [[y[subset] for subset in item] for item in u_m]\n",
    "    x_sub = [[x[subset] for subset in item] for item in u_m]\n",
    "    \n",
    "    subsampleArgs['sumDev1'] = sumDev(y,x,thetaRef)\n",
    "    subsampleArgs['sumDev2'] = sumHessian(x, thetaRef) \n",
    "    subsampleArgs['dev1_sumComponent'] = [[np.sum(devll(y_subitem,x_subitem,thetaRef),axis = 0) for y_subitem,x_subitem in zip(y_item,x_item)] for y_item,x_item in zip(y_sub,x_sub)]\n",
    "    subsampleArgs['dev2_sumComponent'] =[[np.sum(hessianll2(x_subitem,thetaRef),axis = 0) for x_subitem in item] for item in x_sub]\n",
    "    subsampleArgs['llRef'] = loglike_all(y,x,thetaRef)\n",
    "    subsampleArgs['sumProxy'] = proxy_sum(theta,thetaRef,subsampleArgs['llRef'] ,subsampleArgs['sumDev1'],subsampleArgs['sumDev2'])\n",
    "    \n",
    "    \n",
    "    _,loglikeEst, signl,sigma2LL = loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaRef,n,subsampleArgs,getLoglike=True,getGradient=False)\n",
    "    potentialEst = -loglikeEst - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "    \n",
    "    print(\"Start HMCECS\")\n",
    "    try:\n",
    "        for i in xrange(niter):\n",
    "            \n",
    "            lambda_use[i]= lambda_\n",
    "            progress = i*100/niter\n",
    "            \n",
    "            if (np.mod(progress,10)==0 and i>0):\n",
    "                msg = str(progress) + \"% ; nsteps now: \" + str(L) + \"; mean acc: \" + str(np.mean(acc_prob[:i,1]))+ \"; mean acc_u: \" + str(np.mean(acc_prob[:i,0]))\n",
    "                print(msg)\n",
    "                lf = open(logFile,\"a\")\n",
    "                lf.write(msg+ '\\n')\n",
    "                lf.close()\n",
    "                if(saveTempOutput):\n",
    "                    part = int(progress*0.1)\n",
    "                    temp = {'par':theta_keep[:i],'eps':eps_keep,'M':M,'signL':signL[:i]}\n",
    "                    np.save('output/temp'+ str(part) + '.npy',temp)\n",
    "            #-------------------------------------#\n",
    "            if(updateU):\n",
    "                startT = time.time()\n",
    "                potentialCurrent = potentialEst\n",
    "                signl_current = signl\n",
    "                ucurrent = copy.copy(u_m)\n",
    "                Gcurrent = Gc\n",
    "                u_m, Gc, toUpdate = uProp_given_uCurr(m,n,ucurrent,'Exact',lambda_,kappa = unitsPerBlock)\n",
    "                \n",
    "                #------------------------------#\n",
    "                # next update the subsampling dictionary\n",
    "                for b in toUpdate:\n",
    "                    \n",
    "                    y_sub[b] = [y[subset] for subset in u_m[b]] \n",
    "                    x_sub[b] = [x[subset] for subset in u_m[b]] \n",
    "                    subsampleArgs['dev1_sumComponent'][b] = [np.sum(devll(y_subitem,x_subitem,thetaRef),axis = 0) for y_subitem,x_subitem in zip(y_sub[b],x_sub[b])]\n",
    "                    subsampleArgs['dev2_sumComponent'][b] = [np.sum(hessianll2(x_subitem,thetaRef),axis = 0) for x_subitem in x_sub[b]]\n",
    "                    \n",
    "                    \n",
    "                # accept/reject\n",
    "                # 1st compute new (log)likelihood estimate\n",
    "                _,loglikeEst, signl,sigma2LL = loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaRef,n,subsampleArgs,getLoglike=True,getGradient=False)\n",
    "                potentialEst = -loglikeEst - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "                \n",
    "                la_u = np.min([0,-potentialEst+potentialCurrent])\n",
    "                reject_u = np.log(np.random.uniform(0,1,1))>la_u\n",
    "                acc_rate[i,0] = 1-reject_u\n",
    "                acc_prob[i,0] = np.exp(la_u)\n",
    "                \n",
    "                # if reject\n",
    "                if reject_u:\n",
    "                    potentialEst = potentialCurrent\n",
    "                    u_m = copy.copy(ucurrent)\n",
    "                    Gc= Gcurrent\n",
    "                    signl = signl_current\n",
    "                    # update the subset again \n",
    "                    for b in toUpdate:\n",
    "                        y_sub[b] = [y[subset] for subset in u_m[b]] \n",
    "                        x_sub[b] = [x[subset] for subset in u_m[b]] \n",
    "                        subsampleArgs['dev1_sumComponent'][b] = [np.sum(devll(y_subitem,x_subitem,thetaRef),axis = 0) for y_subitem,x_subitem in zip(y_sub[b],x_sub[b])]\n",
    "                        subsampleArgs['dev2_sumComponent'][b] = [np.sum(hessianll2(x_subitem,thetaRef),axis = 0) for x_subitem in x_sub[b]]\n",
    "                        \n",
    "                signL[i,0] = signl\n",
    "                sigmaHat_keep[i,0] = sigma2LL\n",
    "                stopT = time.time()\n",
    "                timePerIter[i,0] = stopT-startT\n",
    "            \n",
    "            #---------------------------------#\n",
    "            # step 2: update theta/u\n",
    "            startT = time.time()\n",
    "            #p = np.random.multivariate_normal(meanp,M,1)[0]\n",
    "            p = Mhalf.dot(np.random.multivariate_normal(meanp,np.identity(len(theta)),1)[0])#np.random.multivariate_normal(meanp,M,1)[0]\n",
    "            \n",
    "            thetacurrent = theta\n",
    "            potentialCurrent = potentialEst\n",
    "            signl_current = signl\n",
    "            Hcurrent = potentialCurrent + kinetic(p,M)\n",
    "            L_keep[i] = L\n",
    "                \n",
    "            # first move half a step\n",
    "            gradEst = loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaRef,n,subsampleArgs,getLoglike=False,getGradient=True)[0] - gradPrior(theta,pfamily,npar,priorPar1,priorPar2)\n",
    "            p = p-0.5*eps*gradEst  \n",
    "            for s in xrange(L):\n",
    "                theta = theta + eps*np.linalg.solve(M,p)\n",
    "                # update dictionary\n",
    "                subsampleArgs['sumProxy'] = proxy_sum(theta,thetaRef,subsampleArgs['llRef'],subsampleArgs['sumDev1'],subsampleArgs['sumDev2'])\n",
    "                if s< (L-1):\n",
    "                    gradEst = loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaRef,n,subsampleArgs,getLoglike=False,getGradient=True)[0] - gradPrior(theta,pfamily,npar,priorPar1,priorPar2)\n",
    "                    p = p-eps*gradEst  \n",
    "                else:\n",
    "                    gradLL,llEstPropose, signl,sigma2LL = loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaRef,n,subsampleArgs,getLoglike=True,getGradient=True)\n",
    "                    gradEst = gradLL - gradPrior(theta,pfamily,npar,priorPar1,priorPar2)\n",
    "                    p = p- 0.5*eps*gradEst\n",
    "                \n",
    "            p = -p\n",
    "            potentialEst = -llEstPropose - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "            H= potentialEst + kinetic(p,M)\n",
    "            la = np.min([0,-H+Hcurrent])\n",
    "            reject = np.log(np.random.uniform(0,1,1)) >la\n",
    "            acc_rate[i,1] = 1-reject\n",
    "            acc_prob[i,1] = np.exp(la)\n",
    "            \n",
    "            # if reject\n",
    "            if reject:\n",
    "                theta = thetacurrent\n",
    "                potentialEst = potentialCurrent\n",
    "                signl = signl_current\n",
    "                subsampleArgs['sumProxy'] = proxy_sum(theta,thetaRef,subsampleArgs['llRef'],subsampleArgs['sumDev1'],subsampleArgs['sumDev2'])\n",
    "                \n",
    "            signL[i,1] = signl\n",
    "            theta_keep[i]  = theta\n",
    "            sigmaHat_keep[i,1] = sigma2LL\n",
    "            stopT = time.time()\n",
    "            timePerIter[i,1] = stopT - startT\n",
    "            \n",
    "            \n",
    "            #-----------------------------------#\n",
    "            # adjust eps on the fly\n",
    "            \n",
    "            if((burnin>0) and (adaptArgs['adapt']==True)):\n",
    "                t = i+1\n",
    "                if((t<= burnin)): #(t>phaseStartPt[1])\n",
    "                    Hbar = (1-1/(t+t0))*Hbar + 1/(t+t0)*(alpha-np.exp(la))\n",
    "                    logEps = mu - np.sqrt(t)/gamma*Hbar\n",
    "                    logEpsBar = t**(-kappa)*logEps + (1-t**(-kappa))*logEpsBar\n",
    "                    eps = np.min([np.exp(logEps),adaptArgs['maxEps']])\n",
    "                    if (eps < 0.00001):\n",
    "                        print('epsilon is getting small!: ' + str(eps))\n",
    "                        if(eps < 0.00001):\n",
    "                            print('epsilon is too small!')\n",
    "                            break\n",
    "                    # omitted the part where adaption parameters were reset when trajectory changed\n",
    "                    eps_keep[t] = eps\n",
    "                    \n",
    "                \n",
    "                if(t==burnin):\n",
    "                    eps = np.min([np.exp(logEpsBar),adaptArgs['maxEps']])\n",
    "                    eps_keep[i:] = eps\n",
    "           #------------------------------------------#\n",
    "            # change trajectory length\n",
    "            if (phase < len(phaseStartPt)):\n",
    "                if((i+1)==phaseStartPt[phase] ):\n",
    "                    currentTrajLength = trajLength[phase]\n",
    "                    phase +=1 #next phase is phase 1\n",
    "            L = np.min([maxSteps,int(round(currentTrajLength/eps,0))])\n",
    "            if(L==0):\n",
    "                    print('number of steps reached 0 !')\n",
    "                    L +=1  \n",
    "            #------------------------------------------#\n",
    "            # UPDATE REF AND EVERYTHING \n",
    "            if( (np.mod(i+1,updateFreq)==0) and (i<burnin) and (adaptArgs['updateRef']==True)):\n",
    "                if ((i+1) == updateFreq):\n",
    "                    thetaRef = np.mean(theta_keep[int(0.5*i):i,:],axis =0)\n",
    "                    \n",
    "                else:\n",
    "                    thetaRef = np.mean(theta_keep[int(0.7*i):i,:],axis =0)\n",
    "                    \n",
    "                \n",
    "                subsampleArgs['sumDev1'] = sumDev(y,x,thetaRef)\n",
    "                subsampleArgs['sumDev2'] = sumHessian(x, thetaRef) \n",
    "                subsampleArgs['dev1_sumComponent'] = [[np.sum(devll(y_subitem,x_subitem,thetaRef),axis = 0) for y_subitem,x_subitem in zip(y_item,x_item)] for y_item,x_item in zip(y_sub,x_sub)]\n",
    "                subsampleArgs['dev2_sumComponent'] =[[np.sum(hessianll2(x_subitem,thetaRef),axis = 0) for x_subitem in item] for item in x_sub]\n",
    "    \n",
    "                subsampleArgs['llRef'] = loglike_all(y,x,thetaRef)\n",
    "                subsampleArgs['sumProxy'] = proxy_sum(theta,thetaRef,subsampleArgs['llRef'] ,subsampleArgs['sumDev1'],subsampleArgs['sumDev2'])\n",
    "                _,loglikeEst, signl,sigma2LL = loglike_estPoissonWithGradient(y_sub,x_sub,theta,thetaRef,n,subsampleArgs,getLoglike=True,getGradient=False)\n",
    "                potentialEst = -loglikeEst - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "                #--------------------------------------#\n",
    "                # updating M\n",
    "                if(updateM):\n",
    "                    # only update M if the number of negative sign is not to large\n",
    "                    if (np.sum(signL[int(0.5*i):i,1]<1)/i < 0.2):\n",
    "                        if(adaptArgs['cov']=='sub'):\n",
    "                            M = hessian_minusLoglike(thetaRef,y,x,u_m,thetaRef,n,subsampleArgs)- hessianPrior(thetaRef,pfamily,priorPar1,priorPar2)\n",
    "                        else:\n",
    "                            M = -(subsampleArgs['sumDev2']) - hessianPrior(thetaRef,pfamily,priorPar1,priorPar2)\n",
    "                            #M = M*1/(m)\n",
    "                        \n",
    "\n",
    "                        if(adaptArgs['diagM']==True):\n",
    "                            M = np.diag(np.diag(M))\n",
    "                    if(np.linalg.cond(M)>10**7):\n",
    "                            print('ill-conditioned covariance matrix!')\n",
    "                            var_theta = np.var(theta_keep[int(i/2):i,:],axis = 0)\n",
    "                            M= np.diag(1/var_theta)\n",
    "                            \n",
    "                    Mhalf = np.linalg.cholesky(M)\n",
    "                    \n",
    "                      \n",
    "    except Warning as w:\n",
    "        print (str(w))\n",
    "    except TypeError as e:\n",
    "        print('type error' + str(e))\n",
    "    except ValueError as e:\n",
    "        print('value error'+ str(e))\n",
    "    except IndexError as e:\n",
    "        print('Index error'+ str(e))\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print('Bye')\n",
    "    lf = open(logFile,\"a\")\n",
    "    lf.write('Run completed successfully')\n",
    "    lf.close()\n",
    "    \n",
    "    finalpar = {'theta':theta_keep}\n",
    "    currentSet = {'theta':theta,'iter':i,'grad':gradEst,'u':u_m,'sigma2_LL':sigma2LL,'eps':eps}\n",
    "    subsampleArgs['lambda'] = lambda_use[0]\n",
    "    # remove some component of the subsample dictionary so that the output is not too large\n",
    "    subsampleArgs['dev1_sumComponent'] = 0 \n",
    "    subsampleArgs['dev2_sumComponent'] = 0\n",
    "    return{'iter':i,'par':finalpar, 'thetaRef':thetaRef, 'acc_rate': acc_rate,'acc_prob':acc_prob,'eps':eps_keep,'sigmaHat':sigmaHat_keep ,\n",
    "    'nsteps':L_keep,'M':M,'runTime':timePerIter,'args':{'adapt':adaptArgs,'hmc':hmcArgs,'sub':subsampleArgs},\n",
    "    'current':currentSet, 'signL':signL,'u0':u0,'un':u_m}\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def hmc_within_gibbs(y,x, theta, thetaRef, burnin,samples,hmcArgs,priorArgs,subsampleArgs,adaptArgs,logFile,saveTempOutput=False):\n",
    "    \"\"\" An attempt to incorporate subsampling into HMC\n",
    "        A new subsample is drawn at each iteration, accept/ reject and then use that subsample to update theta\n",
    "        estimate the gradient using a subsample, and also estimate the Hamiltonian using subsample (with and without bias correction)\n",
    "        Implement with adaptive eps. Fix trajectory length (L*eps)\n",
    "    \"\"\"\n",
    "    # eps is stepsize\n",
    "    # L is number of steps\n",
    "    # M is covariance matrix of p\n",
    "    # correlatedP is a dictionary: true/false: whether we correlate p or not, rho\n",
    "    # set up\n",
    "    n= len(y)\n",
    "    niter =  burnin + samples\n",
    "    npar = len(theta)\n",
    "    #x = data[:,1:]\n",
    "    #----------------------------------#\n",
    "    # arguments for prior\n",
    "    pfamily = priorArgs['family']\n",
    "    priorPar1 = priorArgs['par1']\n",
    "    priorPar2 = priorArgs['par2']\n",
    "    \n",
    "    #----------------------------------#\n",
    "    # HMC arguments\n",
    "    meanp = np.zeros(npar)\n",
    "    eps = hmcArgs['eps']\n",
    "    trajLength = hmcArgs['trajLength']\n",
    "    L= int(round(trajLength[0]/eps,0))\n",
    "    M = hmcArgs['pCov'] \n",
    "    maxSteps = hmcArgs['maxSteps']\n",
    "    \n",
    "    #--------------------------------#\n",
    "    # subsampling arguments\n",
    "    #m,nblock,biascorrect\n",
    "    m = subsampleArgs['subsize']\n",
    "    #nblocks = subsampleArgs['nblocks']\n",
    "    rho = subsampleArgs['rho']\n",
    "    nblocks = 1/(1-rho)\n",
    "    updateFreq = subsampleArgs['updateFreq'] #frequency of updating reference theta\n",
    "    updateU = subsampleArgs['updateU']\n",
    "    biascorrect = subsampleArgs['biasCorrect']\n",
    "    cvorder = subsampleArgs['order']\n",
    "    #dev1_i = devll(data,thetaRef)\n",
    "    #dev1_all = np.sum(dev1_i,axis = 0) #if cannot fit all dev1, switch to calculate sum(dev1)\n",
    "    if(cvorder >0):\n",
    "        dev1_all = sumDev(y,x,thetaRef)\n",
    "    else:\n",
    "        dev1_all =0 \n",
    "    if (cvorder ==2):\n",
    "        dev2_all = sumHessian(x, thetaRef)\n",
    "    else:\n",
    "        dev2_all= 0\n",
    "    llRef = loglike_all(y,x,thetaRef)\n",
    "    \n",
    "    #------------------------------------------#\n",
    "    # parameter for adaptive updating of epsilon\n",
    "    if(adaptArgs['adapt']==True):\n",
    "        Hbar = 0 #Hbar is a sumstat ~ different between the desired acceptance rate and the mean acceptance rate upto time t\n",
    "        alpha = adaptArgs['alpha'] #desired acceptance rate\n",
    "        gamma =adaptArgs['gamma']\n",
    "        kappa = adaptArgs['kappa']\n",
    "        t0 = adaptArgs['t0']\n",
    "        updateM = adaptArgs['updateM']\n",
    "        phaseStartPt = adaptArgs['phaseStartPt']\n",
    "        if(len(phaseStartPt) != len(trajLength)):\n",
    "            print('phaseEndPt must have same length as trajLength')\n",
    "        mu = np.log(10*eps)\n",
    "        logEps = np.log(eps)\n",
    "        logEpsBar = 0\n",
    "        eps_keep = np.zeros(niter)\n",
    "        \n",
    "    else:\n",
    "        eps_keep = eps\n",
    "    phase = 0\n",
    "    currentTrajLength = trajLength[phase]\n",
    "    #-----------------------------------#\n",
    "    # allocate memory for outcome\n",
    "    theta_keep = np.zeros([niter,npar])\n",
    "    \n",
    "    sigmaHat_keep = np.zeros([niter,2]) # after each step\n",
    "    acc_rate = np.zeros([niter,2]) # first column for u, second column for theta\n",
    "    L_keep = np.zeros(niter)\n",
    "    distanceRef = np.zeros(niter) \n",
    "    HDiff = np.zeros(niter)\n",
    "    EDiff = np.zeros(niter)\n",
    "    llEstPropose = np.zeros(niter) \n",
    "    acc_prob = np.zeros([niter,2])   \n",
    "    timePerIter = np.zeros([niter,2])\n",
    "    timeUpdateM = 0\n",
    "    #m_use = np.zeros(niter)\n",
    "    #---------------------------------------------#\n",
    "    # initialize\n",
    "    \n",
    "    u_m, group_indicator = init_u(m,n,'Approx',rho = rho)\n",
    "    #if(len(ustart)>0):\n",
    "    #    u_m = copy.copy(ustart)\n",
    "    u0 = copy.deepcopy(u_m)\n",
    "    y_sub = y[u_m]\n",
    "    x_sub = x[u_m]\n",
    "    #dev1_sub = dev1_i[u_m]\n",
    "    if(cvorder ==0):\n",
    "        dev1_sub = 0\n",
    "    else:\n",
    "        dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "    dev2_sub =0\n",
    "    if(cvorder ==2):\n",
    "        dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar])))\n",
    "    \n",
    "    diff = diff_ind(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,order =cvorder)\n",
    "    sumGrad = sumGradU_est(theta,thetaRef,dev1_all,dev2_all,order = cvorder) #sum of grad at reference value\n",
    "    sigma = (n**2/m*np.var(diff))*biascorrect\n",
    "    \n",
    "    # U = -(loglike_Est-0.5*sigma_LL + logPrior)\n",
    "    potentialEst = -loglike_est(theta,thetaRef,llRef,dev1_all,dev2_all,diff,n,cvorder) - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "    dev2current=0\n",
    "    print(\"Start HMCECS\")\n",
    "    try:\n",
    "        for i in range(0,niter):\n",
    "            numerror = False\n",
    "            progress = i*100/niter\n",
    "            #if np.mod(progress,5)==0:\n",
    "            #    print(str(progress)+ \"% \",end= \"\")\n",
    "            if (np.mod(progress,10)==0 and i>0):\n",
    "                msg = str(progress) + \"% ; nsteps now is: \" + str(L) + \"; mean acc_u is: \" + str(np.mean(acc_prob[:i,0])) + ' and acc_theta: ' + str(np.mean(acc_prob[:i,1]))\n",
    "                print(msg)\n",
    "                lf = open(logFile,\"a\")\n",
    "                lf.write(msg+ '\\n')\n",
    "                lf.close()\n",
    "                if(saveTempOutput):\n",
    "                    part = int(progress*0.1)\n",
    "                    temp = {'par':theta_keep[:i],'eps':eps_keep,'M':M}\n",
    "                    np.save('output/temp'+ str(part) + '.npy',temp)\n",
    "            \n",
    "            #---------------------------------------------------------------------------------    \n",
    "            if(np.mod(i,updateFreq)==0 and i>=updateFreq and i<=burnin and (adaptArgs['updateRef']==True)):\n",
    "                startT = time.time()\n",
    "                # reset reference\n",
    "                if (i == updateFreq):\n",
    "                    thetaRef = np.mean(theta_keep[int(0.5*i):i,:],axis =0)\n",
    "                else:\n",
    "                    thetaRef = np.mean(theta_keep[int(0.7*i):i,:],axis =0)\n",
    "                \n",
    "                #dev1_i = devll(data,thetaRef)\n",
    "                #dev1_all = np.sum(dev1_i,axis = 0)\n",
    "                if(cvorder > 0):\n",
    "                    dev1_all = sumDev(y,x,thetaRef)\n",
    "                    dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "                \n",
    "                dev2_all = sumHessian(x, thetaRef)\n",
    "                \n",
    "                if(cvorder ==2):\n",
    "                    dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar]))) #equivalent to hesianll2\n",
    "                llRef = loglike_all(y,x,thetaRef)\n",
    "                diff = diff_ind(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,cvorder)\n",
    "                sumGrad = sumGradU_est(theta,thetaRef,dev1_all,dev2_all,cvorder)\n",
    "                sigma = (n**2/m*np.var(diff))*biascorrect\n",
    "                \n",
    "                potentialEst = -loglike_est(theta,thetaRef,llRef,dev1_all,dev2_all,diff,n,cvorder) - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "                #-------------------------#\n",
    "                # update M\n",
    "                if(adaptArgs['updateM']):\n",
    "                    \n",
    "                        \n",
    "                        if(adaptArgs['diagM']==True):\n",
    "                            var_theta = np.var(theta_keep[int(i/2):i,:],axis = 0)\n",
    "                            M= np.diag(1/var_theta)\n",
    "                        else:\n",
    "                            M = -(dev2_all) - hessianPrior(thetaRef,pfamily,priorPar1,priorPar2)\n",
    "                            if(np.all(np.linalg.eigvals(M) > 0) == False):\n",
    "                                var_theta = np.var(theta_keep[int(i/2):i,:],axis = 0)\n",
    "                                M= np.diag(1/var_theta)\n",
    "                stopT = time.time()\n",
    "                timeUpdateM = timeUpdateM +  stopT -startT     \n",
    "                \n",
    "            #------------------------------#\n",
    "            # step1 : update u\n",
    "            if(updateU):\n",
    "                startT = time.time()\n",
    "                potentialCurrent = potentialEst\n",
    "                diffcurrent = diff\n",
    "                sigmacurrent = sigma\n",
    "                ucurrent = u_m\n",
    "                \n",
    "                if(nblocks>1):\n",
    "                    u_m,indexToUpdate = uProp_given_uCurr(m, n, ucurrent,'Approx',lambda_ = nblocks, groupindicators= group_indicator)\n",
    "                    blockSize = np.shape(indexToUpdate)[1]\n",
    "                else:\n",
    "                    # update all u\n",
    "                    u_m = np.random.choice(n,m,True)\n",
    "                    indexToUpdate = range(m)\n",
    "                    blockSize=m\n",
    "                #accept/reject\n",
    "                if(cvorder >0):\n",
    "                    dev1current = copy.copy(dev1_sub[indexToUpdate])\n",
    "                if(cvorder==2):\n",
    "                    dev2current = copy.copy(dev2_sub[indexToUpdate])\n",
    "                \n",
    "                y_sub = y[u_m]\n",
    "                x_sub = x[u_m]\n",
    "                if(cvorder >0):\n",
    "                    dev1_sub[indexToUpdate] = devll(y_sub[indexToUpdate],x_sub[indexToUpdate],thetaRef)\n",
    "                if(cvorder==2):\n",
    "                    dev2_sub[indexToUpdate] = np.array(map(hessianll,x_sub[indexToUpdate],thetaRef*np.ones([blockSize,npar])))\n",
    "                \n",
    "                diff = diff_ind(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,cvorder)\n",
    "                sigma = (n**2/m*np.var(diff))*biascorrect\n",
    "                \n",
    "                potentialEst = -loglike_est(theta,thetaRef,llRef,dev1_all,dev2_all,diff,n,cvorder) - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "                # accept new u with probability min(1,posterior_propose/posterior_current), since momentum remained\n",
    "                # where log(posterior_propose/posterior_current) = -log(post_current) - (-log(post_propose)) = U_current - U_propose\n",
    "                \n",
    "                accrate_u = np.exp(np.min([0,-(potentialEst+ 0.5*sigma)+(potentialCurrent+ 0.5*sigmacurrent)]) )\n",
    "                reject_u = (np.random.uniform(0,1,1)>accrate_u)\n",
    "                acc_rate[i,0] = 1-reject_u\n",
    "                acc_prob[i,0] = accrate_u\n",
    "                if reject_u:\n",
    "                    potentialEst = potentialCurrent\n",
    "                    u_m = ucurrent\n",
    "                    diff = diffcurrent\n",
    "                    sigma = sigmacurrent\n",
    "                    if(cvorder >0):\n",
    "                        dev1_sub[indexToUpdate] = dev1current\n",
    "                    if(cvorder==2):\n",
    "                        dev2_sub[indexToUpdate] = dev2current\n",
    "                \n",
    "                y_sub = y[u_m]\n",
    "                x_sub = x[u_m]\n",
    "                sigmaHat_keep[i,0] = n**2/m*np.var(diff) #sigma\n",
    "                stopT = time.time()\n",
    "                timePerIter[i,0] = stopT -startT\n",
    "            #if i==0:\n",
    "            #    ustart = u_m\n",
    "            #------------------------------#\n",
    "            # step2 : update theta|u\n",
    "            # skip the correlated p part, not necessary for now\n",
    "            # sample new momentum\n",
    "            \n",
    "            # set current value\n",
    "            startT = time.time()\n",
    "            p = np.random.multivariate_normal(meanp,M,1)[0]\n",
    "            \n",
    "            thetacurrent = theta\n",
    "            potentialCurrent = potentialEst\n",
    "            diffcurrent = diff\n",
    "            sigmacurrent = sigma\n",
    "            Ecurrent = potentialCurrent + kinetic(p,M) #energy current\n",
    "            Hcurrent = Ecurrent + 0.5*sigmacurrent\n",
    "            L_keep[i] = L\n",
    "            \n",
    "            sumGradCurrent = sumGrad\n",
    "            \n",
    "            # fist move p half step\n",
    "            if(biascorrect == True):\n",
    "                gradEst,s2_temp,dtemp = gradU_estWithCorrection(y_sub,x_sub,thetacurrent,thetaRef,dev1_sub,dev2_sub,sumGradCurrent,n,pfamily,priorPar1,priorPar2,cvorder)\n",
    "            else:\n",
    "                gradEst = gradU_est(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,sumGrad,n,pfamily,priorPar1,priorPar2,cvorder)\n",
    "            \n",
    "            p = p-0.5*eps*gradEst  \n",
    "            \n",
    "            for s in range(0,L):\n",
    "                    # move position\n",
    "                theta = theta+ eps*np.linalg.solve(M,p)\n",
    "                sumGrad = sumGradU_est(theta,thetaRef,dev1_all,dev2_all,cvorder)\n",
    "                    \n",
    "                #move momentum\n",
    "                if(biascorrect ==True):\n",
    "                    gradEst,s2_temp,dtemp = gradU_estWithCorrection(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,sumGrad,n,pfamily,priorPar1,priorPar2,cvorder)\n",
    "                else:\n",
    "                    gradEst = gradU_est(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,sumGrad,n,pfamily,priorPar1,priorPar2,cvorder)\n",
    "                \n",
    "                if((np.any(np.isnan(gradEst))==True)or s2_temp >1000 ):\n",
    "                    accrate = 0\n",
    "                    reject = True\n",
    "                    numerror = True\n",
    "                    break    \n",
    "                if s < (L-1):\n",
    "                    p = p- eps*gradEst\n",
    "                else:\n",
    "                    p = p-0.5*eps*gradEst\n",
    "                \n",
    "            # negate p (not necessary but keep in case change kinetic energy)\n",
    "            if(numerror == False):\n",
    "                p  = -p\n",
    "                \n",
    "                diff = dtemp#diff_ind(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,cvorder)\n",
    "                sigma = (n**2/m*np.var(diff))*biascorrect\n",
    "                llEstPropose[i] = loglike_est(theta,thetaRef,llRef,dev1_all,dev2_all,diff,n,cvorder)\n",
    "                potentialEst = -llEstPropose[i]  - dprior(theta,pfamily,priorPar1,priorPar2)\n",
    "                Epropose = potentialEst + kinetic(p,M)\n",
    "                \n",
    "                H =Epropose + 0.5*sigma # H = E + 0.5*sigma^2LL\n",
    "                \n",
    "                \n",
    "                EDiff[i] = Ecurrent - Epropose \n",
    "                HDiff[i] = Hcurrent - H\n",
    "                \n",
    "                \n",
    "                accrate = np.exp(np.min([0,HDiff[i]]))\n",
    "                reject = np.random.uniform(0,1,1)>accrate\n",
    "            acc_rate[i,1] = 1-reject\n",
    "            acc_prob[i,1] = accrate\n",
    "            if reject:\n",
    "                theta = thetacurrent\n",
    "                potentialEst = potentialCurrent\n",
    "                diff = diffcurrent\n",
    "                sigma = sigmacurrent\n",
    "                sumGrad = sumGradCurrent\n",
    "            \n",
    "            theta_keep[i]=theta                \n",
    "            distanceRef[i] = np.linalg.norm(theta-thetaRef)\n",
    "            sigmaHat_keep[i,1] = sigma\n",
    "            stopT = time.time()\n",
    "            timePerIter[i,1] = stopT- startT    \n",
    "            \n",
    "            #-----------------------------------------#\n",
    "            # updating eps and L on the fly\n",
    "            \n",
    "            if(burnin >0):\n",
    "                t = i+ 1\n",
    "                if(adaptArgs['adapt']==True):\n",
    "                    if(t<= burnin):\n",
    "                    \n",
    "                        Hbar = (1-1/(t+t0))*Hbar + 1/(t+t0)*(alpha-accrate)\n",
    "                        logEps = mu - np.sqrt(t)/gamma*Hbar\n",
    "                        logEpsBar = t**(-kappa)*logEps + (1-t**(-kappa))*logEpsBar\n",
    "                        eps = np.min([np.exp(logEps),adaptArgs['maxEps'],currentTrajLength])\n",
    "                        if (eps <0.00001):\n",
    "                            print('epsilon is getting small!' + str(eps))\n",
    "                            # if eps too small replace with original setting\n",
    "                            #eps = hmcArgs['eps']   \n",
    "                        if(eps <1e-8):\n",
    "                            print('epsilon too small!')\n",
    "                            break                   \n",
    "                        eps_keep[t] = eps\n",
    "                        \n",
    "                        if(phase < len(phaseStartPt)):\n",
    "                            if((i+1)==phaseStartPt[phase]):\n",
    "                                currentTrajLength = trajLength[phase]\n",
    "                                phase +=1 #next phase is phase 1\n",
    "                        L = min(maxSteps,int(round(currentTrajLength/eps,0)))\n",
    "                        if(t==burnin) :\n",
    "                            # t == burnin\n",
    "                            eps = np.min([np.exp(logEpsBar),adaptArgs['maxEps'],currentTrajLength])\n",
    "                            eps_keep[t:] = eps\n",
    "                            L = min(maxSteps,int(round(trajLength[-1]/eps,0)))\n",
    "                            L_fix = max(1,L)\n",
    "                        if L==0:\n",
    "                            print('number of steps reached 0 !')\n",
    "                            L+=1\n",
    "                        \n",
    "                    else:\n",
    "                        L = L_fix\n",
    "                else:\n",
    "                    if t < burnin :\n",
    "                        L = min(maxSteps,int(round(trajLength[0]/eps,0)))\n",
    "                    else:\n",
    "                        L = min(maxSteps,int(round(trajLength[1]/eps,0)))\n",
    "    except Warning as w:\n",
    "        print (str(w))\n",
    "    except TypeError as e:\n",
    "        print('type error' + str(e))\n",
    "    except ValueError as e:\n",
    "        print('value error'+ str(e))\n",
    "    except IndexError as e:\n",
    "        print('Index error'+ str(e))\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print('Bye')\n",
    "    lf = open(logFile,\"a\")\n",
    "    lf.write('Run completed successfully')\n",
    "    lf.close()\n",
    "    \n",
    "    finalpar = {'theta':theta_keep}\n",
    "    currentSet = {'theta':theta,'iter':i,'grad':gradEst,'u':u_m,'sigma2_LL':sigma}\n",
    "    \n",
    "    return{'par':finalpar, 'thetaRef':thetaRef, 'acc_rate': acc_rate,'acc_prob':acc_prob,'eps':eps_keep,'sigmaHat':sigmaHat_keep ,'Ediff' : EDiff,\n",
    "    'nsteps':L_keep,'M':M,'distRef':distanceRef,'Hdist':HDiff,'llEstPropose':llEstPropose,'runTime':timePerIter,'args':{'sub':subsampleArgs,'hmc':hmcArgs},\n",
    "    'current':currentSet,'timeUpdateM':timeUpdateM,'u0':u0,'un':u_m}\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "def gradU_estWithCorrection(y_u,x_u,theta,thetaRef,dev1_u,dev2_u,sumGrad,n,prior,priorPar1,priorPar2,order =2):\n",
    "    \"\"\" FUNCTION TO ESTIMATE GRADIENT USING PROXY , WITH BIAS CORRECTION\n",
    "        \n",
    "    \"\"\"\n",
    "    # dev1_theta: gradient evaluate at current theta for i in u_m\n",
    "    m = len(y_u)\n",
    "    #npar = len(theta)\n",
    "    npar = np.shape(x_u)[1]\n",
    "    dev1_theta = devll(y_u,x_u,theta)\n",
    "    dev1_sum = np.sum((dev1_theta-dev1_u),axis =0)\n",
    "    dev2_sum = np.sum(dev2_u,axis=0)\n",
    "    diff_u = diff_ind(y_u,x_u,theta,thetaRef,dev1_u,dev2_u,order)\n",
    "    sigma = n**2/m*np.var(diff_u)\n",
    "    # bias correction is 1/2sigma_LL so we add the derivative of the bias correction\n",
    "    # grad(d_k) = grad(l_k(theta)) - grad(l_k(theta_bar)) - H_i(theta_bar)(theta-theta_bar)\n",
    "    grad_d_k =  dev1_theta-dev1_u - (theta-thetaRef).dot(dev2_u)\n",
    "    tmp1 = diff_u-np.mean(diff_u)\n",
    "    tmp2 = grad_d_k- np.mean(grad_d_k,axis = 0)\n",
    "    if(order ==2):\n",
    "        gradll  = -(sumGrad + n/m*(dev1_sum - dev2_sum.dot(theta-thetaRef))) + n**2/(m**2)*np.sum(np.array(map(np.multiply,tmp1,tmp2)),axis = 0)\n",
    "    else:\n",
    "        # order = 1 or 0\n",
    "        gradll  = -(sumGrad + n/m*(dev1_sum )) + n**2/(m**2)*np.sum(np.array(map(np.multiply,tmp1,tmp2)),axis = 0)\n",
    "    \n",
    "    gPrior = gradPrior(theta,prior,npar,priorPar1,priorPar2)\n",
    "    out = gradll  - gPrior\n",
    "    return out,sigma,diff_u   \n",
    "\n",
    "       \n",
    "#--------------------------------------------------------------------------------------#\n",
    "def gradU_est(y_sub,x_sub,theta,thetaRef,dev1_u,dev2_u,sumGrad,n,prior,priorPar1,priorPar2,order = 2):\n",
    "    \"\"\" FUNCTION TO ESTIMATE GRADIENT USING PROXY, without bias correction \"\"\"\n",
    "    # dev1_theta: gradient evaluate at current theta for i in u_m\n",
    "    m = len(y_sub)\n",
    "    #npar = len(theta)\n",
    "    \n",
    "    dev1_theta = devll(y_sub,x_sub,theta)\n",
    "    dev1_sum = np.sum((dev1_theta-dev1_u),axis =0)\n",
    "    dev2_sum = np.sum(dev2_u,axis=0)\n",
    "    if(order ==2):\n",
    "        gradll  = -(sumGrad + n/m*(dev1_sum - dev2_sum.dot(theta-thetaRef)))\n",
    "    else:\n",
    "        # order = 1 or 0\n",
    "        gradll  = -(sumGrad + n/m*(dev1_sum ))\n",
    "    gPrior = gradPrior(theta,prior,len(theta),priorPar1,priorPar2)\n",
    "    out = gradll  - gPrior\n",
    "    return out  \n",
    "              \n",
    "                            \n",
    "#------------------------------------------------------------------#              \n",
    "                            \n",
    "def getPrior(priorFam,npar,beta = 0,M = 0,p1 = 0,p2 = None,nu = 20,scale = 10):\n",
    "    if(priorFam == 'gaussian'):\n",
    "        if(p1==0):\n",
    "            p1 = np.zeros(npar) #priorMean\n",
    "            # else p1 is input\n",
    "        if(p2 is None):\n",
    "            p2 = scale**2*np.identity(npar) #priorCov\n",
    "            # else p2 is input\n",
    "    else:\n",
    "        print('invalid options')\n",
    "        p1 =p2 =  np.nan\n",
    "    \n",
    "    priorInfo = {'family':priorFam, 'par1':p1,'par2':p2,'beta':beta} \n",
    "    return priorInfo\n",
    "    \n",
    "#---------------------------------------------------------------#\n",
    "def simData(npar,n):\n",
    "    dataFolder = 'data'+str(npar)+ 'Par/'\n",
    "    dataFile = 'data'+str(npar)+ 'Par'\n",
    "    if not os.path.exists(dataFolder):\n",
    "        os.makedirs(dataFolder)\n",
    "    y_i = np.ones(n)\n",
    "    while sum(y_i) > 0.9*n:    \n",
    "        beta_true = np.array([random.uniform(-5,5)for i in range(0,npar)])\n",
    "        \n",
    "        x_ip = np.ones([n,npar])\n",
    "        for c in range(1,npar):\n",
    "            \n",
    "            x_ip[...,c] = np.random.normal(0,1, n)\n",
    "        p1_i = 1/(1+np.exp(-np.dot(x_ip,beta_true)))\n",
    "        y_i = np.random.binomial(1,p1_i)\n",
    "    \n",
    "    data_ip = np.column_stack((y_i,x_ip))\n",
    "    \n",
    "    np.savetxt(dataFolder + dataFile + '.txt',data_ip)\n",
    "    np.savetxt(dataFolder + 'betaTrue' + '.txt',beta_true)\n",
    "    \n",
    "    \n",
    "\n",
    "def momentEstimator(theta,sign,order=1):\n",
    "    # theta and sign are vector of same length\n",
    "    # default order =1 (expectation)\n",
    "    sumSign = np.sum(sign)\n",
    "    moments_approx = np.sum((theta**order)*sign)/sumSign\n",
    "    return moments_approx\n",
    "    \n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------#\n",
    "# Implementation of SG-HMC\n",
    "def gradEstSG(y,x,theta,n):\n",
    "    \"\"\" \n",
    "    function that estimates gradient by subsampling with no control variate (i.e n/m*sum(grad))\n",
    "    \"\"\"\n",
    "    gradEst = n/len(y)*np.sum(devll(y,x,theta),axis = 0)\n",
    "    return gradEst\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "def sghmcMat(y,x, theta,thetaRef,burnin,samples,eps,trajLength,M,sgpar,priorArgs,adaptArgs,CV=2,logFile='test.txt',saveTempOutput=False):\n",
    "    \"\"\" IMPLEMENTATION OF SGHMC with matrix SGHMC parameters\n",
    "        sgpar is a dictionary of parameters for SG-HMC including eta,alpha and beta\n",
    "    \"\"\"\n",
    "    \n",
    "    niter = burnin + samples\n",
    "    npar = len(theta)\n",
    "    \n",
    "    n = len(y)\n",
    "    theta_keep = np.zeros([niter,npar])\n",
    "    timePerIter = np.zeros(niter)\n",
    "    timeUpdatePar = 0\n",
    "    # arguments for prior\n",
    "    pfamily = priorArgs['family']\n",
    "    priorPar1 = priorArgs['par1']\n",
    "    priorPar2 = priorArgs['par2']\n",
    "    \n",
    "    meanp = np.zeros(len(theta))\n",
    "    m = sgpar['subsize']\n",
    "    C = sgpar['C']\n",
    "    Bhat = 0.5*eps* sgpar['V']\n",
    "    W = C- Bhat\n",
    "    if (np.min(np.linalg.eigvals(W))<0):\n",
    "        print('Warnings: C needs to be > Bhat')\n",
    "    #-------------------------------#\n",
    "    if(CV >0 ):\n",
    "        dev1_all = sumDev(y,x,thetaRef)\n",
    "    if(CV==2):\n",
    "        dev2_all = sumHessian(x, thetaRef)\n",
    "    #llRef = loglike_all(y,x,thetaRef)\n",
    "    u_m = np.random.choice(n,m,True)\n",
    "    y_sub = y[u_m]\n",
    "    x_sub = x[u_m]\n",
    "    if(CV >0):\n",
    "        dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "    else:\n",
    "        dev1_sub = 0\n",
    "    if(CV==2):\n",
    "        dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar])))\n",
    "    phase = 0\n",
    "    L = int(round(trajLength[phase]/eps,0))\n",
    "    print('start SGHMC')\n",
    "    try:\n",
    "        for i in range(0,niter):\n",
    "            progress = i*100/niter\n",
    "            if np.mod(progress,5)==0:\n",
    "                print(str(progress)+ \"% \",end= \"\")\n",
    "            if (np.mod(progress,10)==0 and i>0):\n",
    "                msg = str(progress) + \"%\"\n",
    "                lf = open(logFile,\"a\")\n",
    "                lf.write(msg+ '\\n')\n",
    "                lf.close()\n",
    "                if(saveTempOutput):\n",
    "                    part = int(progress*0.1)\n",
    "                    temp = {'par':theta_keep[:i],'M':M,'eps':eps,'L': L}\n",
    "                    np.save('output/temp'+ str(part) + '.npy',temp)\n",
    "            \n",
    "        \n",
    "            if(np.mod(i,adaptArgs['updateFreq'])==0 and i>=adaptArgs['updateFreq'] and i<=burnin):\n",
    "                startT = time.time()\n",
    "                # reset reference\n",
    "                if (i == adaptArgs['updateFreq']):\n",
    "                    thetaRef = np.mean(theta_keep[int(0.7*i):i,:],axis =0)\n",
    "                else:\n",
    "                    thetaRef = np.mean(theta_keep[int(0.9*i):i,:],axis =0)\n",
    "                \n",
    "                if(CV>0):\n",
    "                    dev1_all = sumDev(y,x,thetaRef)\n",
    "                    dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "                dev2_all = sumHessian(x, thetaRef)\n",
    "                \n",
    "                if(CV==2):\n",
    "                    dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar])))\n",
    "                  \n",
    "                \n",
    "              #  update M          \n",
    "                if(adaptArgs['updateM']):\n",
    "                    \n",
    "                    M = -(dev2_all) - hessianPrior(thetaRef,pfamily,priorPar1,priorPar2)\n",
    "                    if(adaptArgs['diagM']==True):\n",
    "                        M = np.diag(np.diag(M))\n",
    "                    if(np.all(np.linalg.eigvals(M) > 0) == False):\n",
    "                        var_theta = np.var(theta_keep[int(i/2):i,:],axis = 0)\n",
    "                        M= np.diag(1/var_theta) \n",
    "                                  \n",
    "                stopT = time.time()\n",
    "                timeUpdatePar = timeUpdatePar +  stopT -startT                         \n",
    "            \n",
    "            startT = time.time()   \n",
    "            \n",
    "            \n",
    "            p = np.random.multivariate_normal(meanp,M,1)[0]\n",
    "            for s in range(0,L):\n",
    "                u_m = np.random.choice(n,m,True)    \n",
    "                y_sub = y[u_m]\n",
    "                x_sub = x[u_m] \n",
    "                  \n",
    "                #update theta\n",
    "                theta = theta + eps*np.linalg.solve(M,p)\n",
    "                \n",
    "                #update p\n",
    "                if (CV==2):       \n",
    "                           \n",
    "                    dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "                    dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar])))\n",
    "            # move momentum\n",
    "                    sumGrad = sumGradU_est(theta,thetaRef,dev1_all,dev2_all)\n",
    "                    gradUEst = gradU_est(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,sumGrad,n,pfamily,priorPar1,priorPar2)\n",
    "                    \n",
    "                else:\n",
    "                    if(CV==1):\n",
    "                        # use the control variate in the Baker paper\n",
    "                        gradUEst = -dev1_all - n/m*np.sum(devll(y_sub,x_sub,theta)-devll(y_sub,x_sub,thetaRef),axis = 0) - gradPrior(theta,pfamily,npar,priorPar1,priorPar2) \n",
    "                    else:\n",
    "                        gradUEst = - n/m*np.sum(devll(y_sub,x_sub,theta),axis = 0)  - gradPrior(theta,pfamily,npar,priorPar1,priorPar2) \n",
    "                \n",
    "                p = p - eps*gradUEst - eps*np.dot(C,np.linalg.solve(M,p)) + np.random.multivariate_normal(meanp,2*W*eps,1)[0]\n",
    "                \n",
    "                # move position\n",
    "                               \n",
    "            stopT = time.time()\n",
    "            timePerIter[i] = stopT- startT    \n",
    "            \n",
    "            theta_keep[i]= theta\n",
    "            \n",
    "            if((i <burnin) and (adaptArgs['adapt']==True) ):\n",
    "                if ((phase < len(adaptArgs['phaseStartPt'])) and  ((i+1)==adaptArgs['phaseStartPt'][phase])):\n",
    "                    L = int(trajLength[phase]/eps)\n",
    "                    phase = phase+1\n",
    "            \n",
    "    except Warning as w:\n",
    "        print (str(w))\n",
    "    except TypeError as e:\n",
    "        print('type error' + str(e))\n",
    "    except ValueError as e:\n",
    "        print('value error'+ str(e))\n",
    "    except IndexError as e:\n",
    "        print('Index error'+ str(e))\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print('Bye')\n",
    "    lf = open(logFile,\"a\")\n",
    "    lf.write('Run completed successfully')\n",
    "    lf.close()\n",
    "\n",
    "    finalpar = {'theta':theta_keep}\n",
    "    currentSet = {'theta':theta,'iter':i,'grad':gradUEst}\n",
    "    return {'par':finalpar,'eps':eps,'nsteps':L,'args':sgpar,'runTime':timePerIter,'current':currentSet,'M':M,'timeUpdatePar':timeUpdatePar}\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------#\n",
    "# SGLD\n",
    "def sgld(y,x, theta,thetaRef,burnin,samples,eps,subsize,priorArgs,adaptArgs,CV,logFile,saveTempOutput=False):\n",
    "    \"\"\" IMPLEMENTATION OF SGHMC with matrix SGHMC parameters\n",
    "        sgpar is a dictionary of parameters for SG-HMC including eta,alpha and beta\n",
    "    \"\"\"\n",
    "    \n",
    "    niter = burnin + samples\n",
    "    npar = len(theta)\n",
    "    \n",
    "    n = len(y)\n",
    "    theta_keep = np.zeros([niter,npar])\n",
    "    timePerIter = np.zeros(niter)\n",
    "    # arguments for prior\n",
    "    pfamily = priorArgs['family']\n",
    "    priorPar1 = priorArgs['par1']\n",
    "    priorPar2 = priorArgs['par2']\n",
    "    #\n",
    "    m = subsize\n",
    "    \n",
    "    #-------------------------------#\n",
    "    dev1_all = sumDev(y,x,thetaRef)\n",
    "    if (CV==True):\n",
    "        dev2_all = sumHessian(x, thetaRef)\n",
    "    #llRef = loglike_all(y,x,thetaRef)\n",
    "    u_m = np.random.choice(n,m,True)\n",
    "    y_sub = y[u_m]\n",
    "    x_sub = x[u_m]\n",
    "    dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "    dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar])))\n",
    "    try:\n",
    "        for i in range(0,niter):\n",
    "            progress = i*100/niter\n",
    "            if np.mod(progress,5)==0:\n",
    "                print(str(progress)+ \"% \",end= \"\")\n",
    "            if (np.mod(progress,10)==0 and i>0):\n",
    "                msg = str(progress) + \"%\"\n",
    "                lf = open(logFile,\"a\")\n",
    "                lf.write(msg+ '\\n')\n",
    "                lf.close()\n",
    "                if(saveTempOutput):\n",
    "                    part = int(progress*0.1)\n",
    "                    temp = {'par':theta_keep[:i]}\n",
    "                    np.save('output/temp'+ str(part) + '.npy',temp)\n",
    "            \n",
    "            \n",
    "            startT = time.time()   \n",
    "                        \n",
    "            u_m = np.random.choice(n,m,True)           \n",
    "            y_sub = y[u_m]\n",
    "            x_sub = x[u_m]          \n",
    "            dev1_sub = devll(y_sub,x_sub,thetaRef)\n",
    "            if(CV==True):\n",
    "                dev2_sub = np.array(map(hessianll,x_sub,thetaRef*np.ones([m,npar])))\n",
    "                # move momentum\n",
    "                sumGrad = sumGradU_est(theta,thetaRef,dev1_all,dev2_all)\n",
    "                \n",
    "                gradUEst = gradU_est(y_sub,x_sub,theta,thetaRef,dev1_sub,dev2_sub,sumGrad,n,pfamily,priorPar1,priorPar2)\n",
    "                \n",
    "            else:\n",
    "                # first order\n",
    "                gradUEst = -dev1_all - n/m*np.sum(devll(y_sub,x_sub,theta)-dev1_sub,axis = 0) - gradPrior(theta,pfamily,npar,priorPar1,priorPar2) #+ gradPrior(thetaRef,pfamily,npar,priorPar1,priorPar2)\n",
    "                \n",
    "            theta = theta- 0.5*eps*gradUEst+ np.random.multivariate_normal(np.zeros(npar),eps*np.identity(npar),1)[0]\n",
    "                               \n",
    "            stopT = time.time()\n",
    "            timePerIter[i] = stopT- startT    \n",
    "            \n",
    "            theta_keep[i]= theta\n",
    "            \n",
    "    except Warning as w:\n",
    "        print (str(w))\n",
    "    except TypeError as e:\n",
    "        print('type error' + str(e))\n",
    "    except ValueError as e:\n",
    "        print('value error'+ str(e))\n",
    "    except IndexError as e:\n",
    "        print('Index error'+ str(e))\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print('Bye')\n",
    "    lf = open(logFile,\"a\")\n",
    "    lf.write('Run completed successfully')\n",
    "    lf.close()\n",
    "\n",
    "    finalpar = {'theta':theta_keep}\n",
    "    currentSet = {'theta':theta,'iter':i,'grad':gradUEst}\n",
    "    return {'par':finalpar,'eps':eps,'runTime':timePerIter,'current':currentSet}\n",
    " \n",
    " \n",
    "#-------------------------------------------------------------------------------#\n",
    "\n",
    "# maximum likelihood estimator\n",
    "def minusloglike(theta,*args):\n",
    "    y = args[0]\n",
    "    x = args[1]\n",
    "    out = -loglike_all(y,x,theta)\n",
    "    return out\n",
    "def minusDerLL(theta,*args):\n",
    "    y = args[0]\n",
    "    x = args[1]\n",
    "    #npar = len(theta)\n",
    "    const = 1/(1+np.exp(-np.dot(x,theta)))\n",
    "    dev_ind = y.reshape(-1,1)*x - const.reshape(-1,1)*x\n",
    "    gradll= -np.sum(dev_ind,axis =0) \n",
    "    return gradll\n",
    "def minusHess(theta,*args):\n",
    "    y = args[0]\n",
    "    x = args[1]\n",
    "    #npar = len(theta)\n",
    "    sumH = sumHessian(x, theta)\n",
    "    h2 = -sumH\n",
    "    return h2\n",
    "    \n",
    "#------------------------------------------#\n",
    "\n",
    "# maximum posterior estimator- with a N(0,scale^2) prior\n",
    "def minuslogpost(theta,*args):\n",
    "    y = args[0]\n",
    "    x = args[1]\n",
    "    scale = args[2]\n",
    "    npar = len(theta)\n",
    "    out = -loglike_all(y,x,theta) - dprior(theta,'gaussian',np.zeros(npar),scale**2*np.identity(npar))\n",
    "    return out\n",
    "def minusDerPost(theta,*args):\n",
    "    y = args[0]\n",
    "    x = args[1]\n",
    "    scale = args[2]\n",
    "    npar = len(theta)\n",
    "    const = 1/(1+np.exp(-np.dot(x,theta)))\n",
    "    dev_ind = y.reshape(-1,1)*x - const.reshape(-1,1)*x\n",
    "    gradlp= -np.sum(dev_ind,axis =0) - gradPrior(theta,'gaussian',npar,np.zeros(npar),scale**2*np.identity(npar))\n",
    "    return gradlp\n",
    "def minusHessPost(theta,*args):\n",
    "    y = args[0]\n",
    "    x = args[1]\n",
    "    scale = args[2]\n",
    "    npar = len(theta)\n",
    "    sumH = sumHessian(x, theta)\n",
    "    h2 = -sumH - hessianPrior(theta,'gaussian',np.zeros(npar),scale**2*np.identity(npar))\n",
    "    return h2\n",
    "    \n",
    "#-------------------------------------------#\n",
    "def find_opt(gamma, algorithm, rho,intitial=50000):\n",
    "    # return optimal lambda for exact and optimal m for approximate algorithm\n",
    "    if(algorithm == 'Exact'):\n",
    "        minlambda = int(np.round(1/(1-rho)))\n",
    "        lambda_opt = int(np.ceil(np.exp(-0.1022 + 0.4904*np.log(np.max(gamma)))/minlambda))*minlambda\n",
    "        return lambda_opt\n",
    "    elif(algorithm=='Approx'):\n",
    "        min_m = int(np.round(1/(1-rho)))\n",
    "        m_opt = int(np.ceil(scipy.optimize.minimize(CT_approx,intitial,args = (14249843,0.99)).x/min_m))*min_m\n",
    "        return m_opt\n",
    "def varLogLApprox(gamma,m):\n",
    "    varl = gamma/m + gamma**2/(2*m**3)\n",
    "    return varl        \n",
    "def CT_approx(m,gamma,rho):\n",
    "    sig_approx = np.sqrt(varLogLApprox(gamma,m))\n",
    "    IF_approx = IF_factor_exact(rho, sig_approx)\n",
    "    return m*IF_approx\n",
    "  \n",
    "#----------------------------------------------------#\n",
    "def IF_factor_exact(rho, sig):\n",
    "    \"\"\"\n",
    "    MATLAB code from MNT that I translate to Python\n",
    "    NOTE: Input here is standard deviation and not variance\n",
    "    \n",
    "    NOTE that this is for the case when we have correlation between the estimators. If not, set rho = 0, and we get the expression in Pitt et al.\n",
    "    \"\"\"\n",
    "    #function out = IF_factor(rho,sig)    \n",
    "    mu_star = -sig*rho*np.sqrt((1-rho)/(1+rho))\n",
    "    sig2_star = (1-rho)/(1+rho)\n",
    "    tau = sig*np.sqrt(1-rho**2)\n",
    "    \n",
    "    #p = @(w) normcdf(w+tau)-exp(-w*tau-tau^2/2)*normcdf(w);    \n",
    "    p = lambda w: sps.norm.cdf(w+tau) - np.exp(-w*tau-tau**2/2)*sps.norm.cdf(w)\n",
    "        \n",
    "    # p_prime = @(w) normpdf(w+tau)+exp(-w*tau-tau^2/2)*(tau*normcdf(w)-normpdf(w));\n",
    "    p_prime = lambda w: sps.norm.pdf(w+tau) + np.exp(-w*tau-tau**2/2)*(tau*sps.norm.cdf(w) - sps.norm.pdf(w))\n",
    "    \n",
    "    #phi_prime = @(w) -w*normpdf(w);\n",
    "    phi_prime = lambda w:  -w*sps.norm.pdf(w) \n",
    "    \n",
    "    #p_2prime = @(w) phi_prime(w+tau)-exp(-w*tau-tau^2/2)*(tau^2*normcdf(w)-2*tau*normpdf(w)+phi_prime(w));\n",
    "    p_2prime = lambda w: phi_prime(w+tau)-np.exp(-w*tau-tau**2/2)*(tau**2*sps.norm.cdf(w)-2*tau*sps.norm.pdf(w)+phi_prime(w))\n",
    "    \n",
    "    #p_3prime = @(w) ((w+tau)^2-1)*normpdf(w+tau)+exp(-w*tau-tau^2/2)*(tau^3*normcdf(w)-normpdf(w)*(3*tau^2+3*tau*w+w^2-1));\n",
    "    p_3prime = lambda w: ((w+tau)**2-1)*sps.norm.pdf(w+tau)+np.exp(-w*tau-tau**2/2)*(tau**3*sps.norm.cdf(w)-sps.norm.pdf(w)*(3*tau**2+3*tau*w+w**2-1))\n",
    "    \n",
    "    # p_4prime = @(w) (3*(w+tau)-(w+tau)^3)*normpdf(w+tau)-exp(-w*tau-tau^2/2)*( tau^4*normcdf(w)-normpdf(w)*(4*tau^3+6*tau^2*w+4*tau*w^2-4*tau+w^3-3*w) )\n",
    "    p_4prime = lambda w:  (3*(w+tau)-(w+tau)**3)*sps.norm.pdf(w+tau)-np.exp(-w*tau-tau**2/2)*(tau**4*sps.norm.cdf(w)-sps.norm.pdf(w)*(4*tau**3+6*tau**2*w+4*tau*w**2-4*tau+w**3-3*w))\n",
    "    \n",
    "    #f = @(w) (1+p(w))/(1-p(w));\n",
    "    f = lambda w:  (1+p(w))/(1-p(w))\n",
    "   \n",
    "    #f_prime = @(w) p_prime(w)*(1+f(w))/(1-p(w));\n",
    "    f_prime = lambda w: p_prime(w)*(1+f(w))/(1-p(w))\n",
    "    \n",
    "    #f_2prime = @(w) ( p_2prime(w)*(1+f(w))+2*p_prime(w)*f_prime(w) )/(1-p(w));\n",
    "    f_2prime = lambda w: (p_2prime(w)*(1+f(w))+2*p_prime(w)*f_prime(w) )/(1-p(w))\n",
    "    \n",
    "    #f_3prime = @(w) ( p_3prime(w)*(1+f(w))+3*p_2prime(w)*f_prime(w)+3*p_prime(w)*f_2prime(w) )/(1-p(w));\n",
    "    f_3prime = lambda w: (p_3prime(w)*(1+f(w))+3*p_2prime(w)*f_prime(w)+3*p_prime(w)*f_2prime(w) )/(1-p(w));\n",
    "    \n",
    "    #f_4prime = @(w) ( p_4prime(w)*(1+f(w))+4*p_3prime(w)*f_prime(w)+6*p_2prime(w)*f_2prime(w)+4*p_prime(w)*f_3prime(w) )/(1-p(w));\n",
    "    f_4prime = lambda w: (p_4prime(w)*(1+f(w))+4*p_3prime(w)*f_prime(w)+6*p_2prime(w)*f_2prime(w)+4*p_prime(w)*f_3prime(w) )/(1-p(w))\n",
    "    \n",
    "    ans = f(mu_star)+1/2*f_2prime(mu_star)*sig2_star+1/8*f_4prime(mu_star)*sig2_star**2\n",
    "    if np.isinf(ans) or np.isnan(ans):\n",
    "        print (\"Inf or Nan in IF expression. Variance is %s\" % sig**2)\n",
    "        print (\"Stir optimizer away from here\")\n",
    "        return 10e100\n",
    "    else:\n",
    "        return f(mu_star)+1/2*f_2prime(mu_star)*sig2_star+1/8*f_4prime(mu_star)*sig2_star**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import R functions to compute ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "# diagnostic\n",
    "r = robjects.r\n",
    "r.library('coda')\n",
    "EffectiveSize = r['effectiveSize'] # Get function of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nparray2rmatrix(x):\n",
    "    \"\"\"\n",
    "    Converts a nparray to an r matrix.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nr, nc = x.shape\n",
    "    except ValueError:\n",
    "        nr = x.shape[0]\n",
    "        nc = 1\n",
    "    xvec = robjects.FloatVector(x.transpose().reshape((x.size)))\n",
    "    xr = robjects.r.matrix(xvec, nrow=nr, ncol=nc)\n",
    "    return xr\n",
    "    \n",
    "def IF(thetaDraws, burnin):\n",
    "    \"\"\"\n",
    "    Compute the computational time which is defined as CT = IF*n, where n is the total number of density evaluations the algorithm has performed and IF is the inefficiency factor\n",
    "    The function returns CT for each parameter\n",
    "    \"\"\"\n",
    "    pVar = thetaDraws.shape[1]    \n",
    "    IF= np.zeros(pVar)\n",
    "    ESS = np.zeros(pVar)\n",
    "    for j in xrange(pVar):\n",
    "        draws = thetaDraws[burnin:, j]\n",
    "        \n",
    "        # Compute effective samples \n",
    "        PosteriorDrawsBetaRFormat = nparray2rmatrix(draws)\n",
    "        ESS[j] = np.array(EffectiveSize(PosteriorDrawsBetaRFormat))\n",
    "        IF[j] = len(draws)/ESS[j]\n",
    "    \n",
    "    return  IF, ESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code\n",
    "# code to implement HMC-ECS for logistic regression\n",
    "# please have a look at what each line is doing before running the script\n",
    "# this code is written in python 2.7. \n",
    "# If you're using python 3, then change the \"from __future__ import\" to \"import\"\n",
    "from __future__ import division\n",
    "import os\n",
    "#-------------------------------------------------#\n",
    "# load some additional library for plotting\n",
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "import numdifftools as nd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 8136.740375\n",
      "         Iterations: 10\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 20\n",
      "         Hessian evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/miaocai/Dropbox/Aim2/@HMCECS')\n",
    "npar = 10\n",
    "np.random.seed(1234)   \n",
    "dataFile = 'data'+str(npar)+ 'Par'\n",
    "\n",
    "#------------------------------------------------#   \n",
    "data_ip = np.loadtxt(dataFile +'.txt')\n",
    "#beta_true = np.loadtxt('betaTrue.txt') \n",
    "\n",
    "n= len(data_ip)\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# define prior\n",
    "priorInfo = getPrior('gaussian',npar,scale = 5) #Assume N(0,5^2) for all parameters\n",
    "\n",
    "# initialize\n",
    "betaMP = minimize(minuslogpost, np.zeros(npar), args = (data_ip[:,0],data_ip[:,1:],5), method='Newton-CG', \n",
    "                  jac = minusDerPost,hess = minusHessPost, options = {'disp': True})\n",
    "beta_bar = betaMP['x']\n",
    "\n",
    "# mass matrix M. default is identity matrix\n",
    "pCov = np.identity(npar)\n",
    "beta = np.random.multivariate_normal(beta_bar,1e-4*np.linalg.inv(pCov),1)[0]\n",
    "\n",
    "# There are quite a numeber of tuning parameters needed for HMCECS\n",
    "# They need to be specified as input for the main function\n",
    "\n",
    "burnin = 600\n",
    "samples = 1000\n",
    "logFile = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5eaa1208b6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                        'updateU':True,'rho' : 0.99,'order':2}\n\u001b[1;32m     33\u001b[0m     output = hmc_within_gibbs(data_ip[:,0],data_ip[:,1:], beta, beta_bar,burnin,samples,\n\u001b[0;32m---> 34\u001b[0;31m                               hmcInfo,priorInfo,subsampleApprox,adaptInfoSub,logFile)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# some additional settings for subsampling part:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f8e00f140de7>\u001b[0m in \u001b[0;36mhmc_within_gibbs\u001b[0;34m(y, x, theta, thetaRef, burnin, samples, hmcArgs, priorArgs, subsampleArgs, adaptArgs, logFile, saveTempOutput)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mdev2_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessianll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetaRef\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnpar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetaRef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev1_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev2_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcvorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0msumGrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msumGradU_est\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetaRef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev1_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev2_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvorder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sum of grad at reference value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbiascorrect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8de7aec2ab7e>\u001b[0m in \u001b[0;36mdiff_ind\u001b[0;34m(y_u, x_u, theta, thetaref, d1_u, d2_u, order)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0mlltrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloglike_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetaref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md1_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md2_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlltrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8de7aec2ab7e>\u001b[0m in \u001b[0;36mproxy_ind\u001b[0;34m(y, x, theta, thetaref, d1, d2, order)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllref\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthetaref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthetaref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthetaref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;31m#---------------------------------------------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'map'"
     ]
    }
   ],
   "source": [
    "# 1. Arguments for adaptation.\n",
    "# Note that when we set M=I then epsilon is small and I don't spend too much time in the first few iterations\n",
    "# This is obtained by by changing epsilon*L everytime I think M changes a lot. \n",
    "# Note that M is updated every time the reference for control variate is updated\n",
    "# Not necessary when M is fixed or you have the optimal M. \n",
    "# The setting are arbitrary- just make sure that we have enough iterations with the desired epsilon*L \n",
    "# and the value in the last 2 elements of trajLength is your desired epsilon*L\n",
    "phaseStart = np.array([   1,100,200, burnin]) #if M is fixed : np.array([   1,burnin])\n",
    "trajLength =np.array([ 0.1,1.2,1.2 ,1.2 ]) # if M is fixed : np.array([ 1 ,1 ])\n",
    "\n",
    "adaptInfoSub = {'adapt':True,'alpha': 0.80,'gamma': 0.05, 'kappa': 0.75,'t0':10,'updateM':True,\n",
    "'phaseStartPt': phaseStart,'tol': 1e-8,'diagM':False,'maxEps':1,'cov':'full','updateRef':True}\n",
    "\n",
    "# some additional information for the hmc step\n",
    "hmcInfo = {'eps':0.001,'trajLength':trajLength,'pCov': pCov,'maxSteps':300}\n",
    "\n",
    "# choose either the perturbed or signed (exact) version\n",
    "algorithm = 'perturbed'\n",
    "\n",
    "\n",
    "if (algorithm == 'perturbed'):\n",
    "    # some additional settings for subsampling part: \n",
    "    # subsize: subsample size. Note that in practice you should estimate the variance of \n",
    "    #          the log-likelihood estimator and use that information to set the subsample size\n",
    "    # biasCorrect: (True/False) for perturbed version only, whether to add the bias correction to \n",
    "    #              likelihood and gradient evaluation\n",
    "    # updateFreq: how often the reference theta* is updated (eg: every 200 iterations)\n",
    "    # updateU: (True/False) whether to run the first step of HMCECS or not\n",
    "    # rho: correlation in the blocking of subsample. rho = 0.99 is equivalent to update 1% of the subsample only\n",
    "    # order: the order of the Taylor expansion \n",
    "    subsampleApprox = {'subsize': int(n*0.01),'biasCorrect':True,'updateFreq':200,\n",
    "                       'updateU':True,'rho' : 0.99,'order':2}\n",
    "    output = hmc_within_gibbs(data_ip[:,0],data_ip[:,1:], beta, beta_bar,burnin,samples,\n",
    "                              hmcInfo,priorInfo,subsampleApprox,adaptInfoSub,logFile)\n",
    "else:\n",
    "    # some additional settings for subsampling part: \n",
    "    # subsize: subsample \"chunk\" size. Please refer to paper\n",
    "    lambda_ = 100\n",
    "    dhat_mean = 0\n",
    "    a_ = dhat_mean-lambda_\n",
    "    mb = 30#\n",
    "    # note that signed HMCECS are implemented with 2nd order Taylor expansion control variate only\n",
    "    subsampleExact = {'subsize': mb,'lambda':lambda_,'a':a_,'biasCorrect':True,\n",
    "                      'updateFreq':200,'updateU':True,'rho' : 0.99,'order':2}\n",
    "    output = hmc_ecs_Exact(data_ip[:,0],data_ip[:,1:], beta, beta_bar,burnin,samples,\n",
    "                           hmcInfo,priorInfo,subsampleExact,adaptInfoSub,logFile)\n",
    "\n",
    "# note that the output is an dictionary\n",
    "np.save('HMCECS1.npy',output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------#\n",
    "# to test- full data HMC\n",
    "\n",
    "adaptInfoHMC = {'adapt':True,'alpha': 0.80,'gamma': 0.05, 'kappa': 0.75,'t0':10,'updateM':True,\n",
    "                'phaseStartPt': phaseStart,'tol': 1e-8, 'diagM':False,'maxEps':1,'updateFreq':200}\n",
    "\n",
    "logFile ='test.txt'\n",
    "\n",
    "hmcFull = hmc(data_ip[:,0],data_ip[:,1:], beta,burnin,samples,0.001,trajLength,300,\n",
    "              pCov,priorInfo,adaptInfoHMC,logFile)\n",
    "\n",
    "np.save('HMCFit.npy',hmcFull)\n",
    "\n",
    "\n",
    "#for p in xrange(npar):\n",
    "#    plt.figure(p)\n",
    "#    plt.plot(hmcFull['par']['theta'][:,p],label = 'hmc')\n",
    "#    plt.plot(output['par']['theta'][:,p],label = 'hmcecs')\n",
    "#    plt.legend()\n",
    "\n",
    "#----------------------------------------------------#\n",
    "# SGHMC\n",
    "runSGHMC = False\n",
    "if (runSGHMC):\n",
    "    ControlVariate = 2\n",
    "    m = int(n*0.01)\n",
    "    epsilon = 0.2\n",
    "    sghmcPar = {'C':np.identity(npar),'V':np.zeros([npar,npar]),'subsize':m}\n",
    "    adaptSGHMC = {'updateFreq':200, 'updateM':False,'diagM':False,'adapt':False,'phaseStartPt': [1]}\n",
    "    \n",
    "    sghmc_1= sghmcMat(data_ip[:,0],data_ip[:,1:], beta,beta_bar,burnin,samples,epsilon,[1.2],\n",
    "                      hmcFull['M'],sghmcPar,priorInfo,adaptSGHMC,ControlVariate,logFile,saveTempOutput=False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_ind(y_u,x_u,theta,thetaref,d1_u,d2_u=0,order = 2):\n",
    "    \n",
    "    # u is the vector of index of obs included\n",
    "    #evaluate d_i = l_i- q_i\n",
    "    lltrue = loglike_ind(y_u,x_u,theta)\n",
    "    \n",
    "    proxy = proxy_ind(y_u,x_u,theta,thetaref,d1_u,d2_u,order)\n",
    "    diff = np.array(lltrue) - np.array(proxy)\n",
    "    return diff\n",
    "diff_ind()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7290bbfa1276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloglike_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-8de7aec2ab7e>\u001b[0m in \u001b[0;36mloglike_ind\u001b[0;34m(y, x, theta)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnpar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnpar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "loglike_ind([1, 2, 3],[4, 5, 6],[2, 3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
