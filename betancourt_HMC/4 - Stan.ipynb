{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module stan_utility:\n",
      "\n",
      "NAME\n",
      "    stan_utility\n",
      "\n",
      "DESCRIPTION\n",
      "    ############################################################\n",
      "    # Copyright 2019 Michael Betancourt\n",
      "    # Licensed under the new BSD (3-clause) license:\n",
      "    #\n",
      "    # https://opensource.org/licenses/BSD-3-Clause\n",
      "    ############################################################\n",
      "\n",
      "FUNCTIONS\n",
      "    check_all_diagnostics(fit, max_treedepth=10, quiet=False)\n",
      "        Checks all MCMC diagnostics\n",
      "    \n",
      "    check_div(fit, quiet=False)\n",
      "        Check transitions that ended with a divergence\n",
      "    \n",
      "    check_energy(fit, quiet=False)\n",
      "        Checks the energy fraction of missing information (E-FMI)\n",
      "    \n",
      "    check_n_eff(fit, quiet=False)\n",
      "        Checks the effective sample size per iteration\n",
      "    \n",
      "    check_rhat(fit, quiet=False)\n",
      "        Checks the potential scale reduction factors\n",
      "    \n",
      "    check_treedepth(fit, max_treedepth=10, quiet=False)\n",
      "        Check transitions that ended prematurely due to maximum tree depth limit\n",
      "    \n",
      "    compile_model(filename, model_name=None, **kwargs)\n",
      "        This will automatically cache models - great if you're just running a\n",
      "        script on the command line.\n",
      "        \n",
      "        See http://pystan.readthedocs.io/en/latest/avoiding_recompilation.html\n",
      "    \n",
      "    parse_warning_code(warning_code)\n",
      "        Parses warning code into individual failures\n",
      "    \n",
      "    partition_div(fit)\n",
      "        Returns parameter arrays separated into divergent and non-divergent transitions\n",
      "\n",
      "FILE\n",
      "    c:\\users\\miaocai\\dropbox\\@hmcecs\\betancourt_hmc\\stan_utility.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Copyright 2019 Michael Betancourt\n",
    "# Licensed under the new BSD (3-clause) license:\n",
    "#\n",
    "# https://opensource.org/licenses/BSD-3-Clause\n",
    "############################################################\n",
    "\n",
    "############################################################\n",
    "# Initial setup\n",
    "############################################################\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "import pystan\n",
    "import stan_utility\n",
    "\n",
    "help(stan_utility)\n",
    "\n",
    "light=\"#DCBCBC\"\n",
    "light_highlight=\"#C79999\"\n",
    "mid=\"#B97C7C\"\n",
    "mid_highlight=\"#A25050\"\n",
    "dark=\"#8F2727\"\n",
    "dark_highlight=\"#7C0000\"\n",
    "green=\"#00FF00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate the computation of Markov chain Monte Carlo estimators, let's define a _Welford accumulator_ that computes empirical summaries of a sample in a single pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welford_summary(x, L = 100):\n",
    "  summary = [0] * (L + 1)\n",
    "  for n in range(len(x)):\n",
    "    delta = x[n] - summary[0]\n",
    "    summary[0] += delta / (n + 1)\n",
    "    for l in range(L):\n",
    "      if n > l:\n",
    "        summary[l + 1] += delta * (x[n - l] - summary[0])\n",
    "\n",
    "  norm = 1.0 / (len(x) - 1)\n",
    "  for l in range(L): summary[l + 1] *= norm\n",
    "  return summary\n",
    "\n",
    "# We can then use the Welford accumulator output to compute the\n",
    "# Markov chain Monte Carlo estimators and their properties\n",
    "def compute_mcmc_stats(x, L = 20):\n",
    "  summary = welford_summary(x, L)\n",
    "  \n",
    "  mean = summary[0]\n",
    "  var = summary[1]\n",
    "  acov = summary[1:(L + 1)]\n",
    "  \n",
    "  # Compute the effective sample size\n",
    "  rho_hat_s = [0] * L\n",
    "  rho_hat_s[1] = acov[1] / var\n",
    "  \n",
    "  # First we transform our autocovariances into Geyer's initial positive sequence\n",
    "  max_s = 1\n",
    "  for s in [ 2 * i + 1 for i in range((L - 1) / 2) ]:\n",
    "    rho_hat_even = acov[s + 1] / var\n",
    "    rho_hat_odd = acov[s + 2] / var;\n",
    "    \n",
    "    max_s = s + 2  \n",
    "    \n",
    "    if rho_hat_even + rho_hat_odd > 0:\n",
    "      rho_hat_s[s + 1] = rho_hat_even\n",
    "      rho_hat_s[s + 2] = rho_hat_odd\n",
    "    else:   \n",
    "      break\n",
    "  \n",
    "  # Then we transform this output into Geyer's initial monotone sequence\n",
    "  for s in [ 2 * i + 3 for i in range((max_s - 2)/ 2) ]:\n",
    "    if rho_hat_s[s + 1] + rho_hat_s[s + 2] > rho_hat_s[s - 1] + rho_hat_s[s]:\n",
    "      rho_hat_s[s + 1] = 0.5 * (rho_hat_s[s - 1] + rho_hat_s[s])\n",
    "      rho_hat_s[s + 2] = rho_hat_s[s + 1]\n",
    "  \n",
    "  ess = len(x) / (1.0 + 2 * sum(rho_hat_s))\n",
    "  \n",
    "  return [mean, math.sqrt(var / ess), math.sqrt(var), ess]\n",
    "\n",
    "def compute_running_estimator(x):\n",
    "  N = len(x)\n",
    "  stride = 50\n",
    "  M = N / stride\n",
    "\n",
    "  iters = [ stride * (i + 1) for i in range(M) ]\n",
    "  \n",
    "  x1_mean = [0] * M \n",
    "  x1_se = [0] * M\n",
    "\n",
    "  for m in range(M):\n",
    "    running_samples = x0[0:iters[m]]\n",
    "    mcmc_stats = compute_mcmc_stats(running_samples)\n",
    "    x1_mean[m] = mcmc_stats[0]\n",
    "    x1_se[m] = mcmc_stats[1]\n",
    "    \n",
    "  return iters, x1_mean, x1_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1 - concentration_of_measure.ipynb',\n",
       " '1 - concentration_of_measure.pdf',\n",
       " '1 - concentration_of_measure.py',\n",
       " '2 - markov_chain_monte_carlo.py',\n",
       " '2 - MCMC.ipynb',\n",
       " '2 - MCMC.pdf',\n",
       " '3 - hamiltonian_monte_carlo.py',\n",
       " '3 - HMC.ipynb',\n",
       " '3 - HMC.pdf',\n",
       " '4 - Stan.ipynb',\n",
       " '4 - stan.py',\n",
       " 'fit_data.stan',\n",
       " 'normal.stan',\n",
       " 'simulate_data.stan',\n",
       " 'stan_utility.py',\n",
       " 'student_t.stan',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_7b4bba0d88c133f5c4d5d7d26b852ef0 NOW.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Dropbox\\@HMCECS\\betancourt_HMC\\stan_utility.py\u001b[0m in \u001b[0;36mcompile_model\u001b[1;34m(filename, model_name, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cached-model-7b4bba0d88c133f5c4d5d7d26b852ef0.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2d093229d393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compile Stan program and fit with dynamic Hamiltonian Monte Carlo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstan_utility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'normal.stan'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4838282\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Check diagnostics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\@HMCECS\\betancourt_HMC\\stan_utility.py\u001b[0m in \u001b[0;36mcompile_model\u001b[1;34m(filename, model_name, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStanModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\p36ws\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, charset, model_name, model_code, stanc_ret, include_paths, boost_lib, eigen_lib, verbose, obfuscate_model_name, extra_compile_args)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[0mbuild_extension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mredirect_stderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\p36ws\\lib\\distutils\\command\\build_ext.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    306\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                                      \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                                      force=self.force)\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mcustomize_compiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# If we are cross-compiling, init the compiler now (if we are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\p36ws\\lib\\distutils\\ccompiler.py\u001b[0m in \u001b[0;36mnew_compiler\u001b[1;34m(plat, compiler, verbose, dry_run, force)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;31m# with classes that expect verbose to be the first positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;31m# argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\p36ws\\lib\\distutils\\cygwinccompiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, verbose, dry_run, force)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mCygwinCCompiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;31m# ld_version >= \"2.13\" support -shared so use it instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\p36ws\\lib\\distutils\\cygwinccompiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, verbose, dry_run, force)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# same as the rest of binutils ( also ld )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# dllwrap 2.10.90 is buggy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld_version\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;34m\"2.10.90\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinker_dll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gcc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "# Compile Stan program and fit with dynamic Hamiltonian Monte Carlo\n",
    "model = stan_utility.compile_model('normal.stan')\n",
    "fit = model.sampling(seed=4838282)\n",
    "\n",
    "# Check diagnostics\n",
    "stan_utility.check_all_diagnostics(fit)\n",
    "\n",
    "# Check MCMC estimators\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student-t Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = stan_utility.compile_model('student_t.stan')\n",
    "\n",
    "# 100 degrees of freedom\n",
    "data = dict(nu = 100)\n",
    "fit100 = model.sampling(data=data, seed=4838282,\n",
    "                        control=dict(metric=\"unit_e\", stepsize=0.7, adapt_engaged=False))\n",
    "stan_utility.check_all_diagnostics(fit100)\n",
    "\n",
    "sampler_params = fit100.get_sampler_params(inc_warmup=False)\n",
    "stepsizes100 = [sampler_params[n]['stepsize__'][0] \n",
    "                for n in range(4) ]\n",
    "times100 = [stepsizes100[n] * x for n in range(4)\n",
    "          for x in sampler_params[n]['n_leapfrog__'] ]\n",
    "energies100 = [x for y in sampler_params for x in y['energy__']]\n",
    "\n",
    "x0 = fit100.extract(permuted=False)[:,:,0].flatten()\n",
    "iters, x1_mean, x1_se = compute_running_estimator(x0)\n",
    "\n",
    "plot.fill_between(iters, \n",
    "                  [ x1_mean[m] - 2 * x1_se[m] for m in range(len(iters)) ],\n",
    "                  [ x1_mean[m] + 2 * x1_se[m] for m in range(len(iters)) ],\n",
    "                  facecolor=light, color=light)\n",
    "plot.plot(iters, x1_mean, color=dark)\n",
    "plot.plot([iters[0], iters[-1]], [0, 0], color='grey', linestyle='--')\n",
    "\n",
    "plot.gca().set_xlim([0, 4000])\n",
    "plot.gca().set_xlabel(\"Iteration\")\n",
    "plot.gca().set_ylim([-0.5, 0.5])\n",
    "plot.gca().set_ylabel(\"Monte Carlo Estimator\")\n",
    "\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(nu = 5)\n",
    "fit5 = model.sampling(data=data, seed=4838282, \n",
    "                      control=dict(metric=\"unit_e\", stepsize=0.7, adapt_engaged=False))\n",
    "stan_utility.check_all_diagnostics(fit5)\n",
    "\n",
    "sampler_params = fit5.get_sampler_params(inc_warmup=False)\n",
    "stepsizes5 = [sampler_params[n]['stepsize__'][0] \n",
    "              for n in range(4) ]\n",
    "times5 = [stepsizes5[n] * x for n in range(4)\n",
    "          for x in sampler_params[n]['n_leapfrog__'] ]\n",
    "energies5 = [x for y in sampler_params for x in y['energy__']]\n",
    "\n",
    "# 2 degrees of freedom -- no more component variances!\n",
    "data = dict(nu = 2)\n",
    "fit2 = model.sampling(data=data, seed=4838282,\n",
    "                      control=dict(metric=\"unit_e\", stepsize=0.7, adapt_engaged=False))\n",
    "stan_utility.check_all_diagnostics(fit2)\n",
    "\n",
    "sampler_params = fit2.get_sampler_params(inc_warmup=False)\n",
    "stepsizes2 = [sampler_params[n]['stepsize__'][0] \n",
    "              for n in range(4) ]\n",
    "times2 = [stepsizes2[n] * x for n in range(4)\n",
    "          for x in sampler_params[n]['n_leapfrog__'] ]\n",
    "energies2 = [x for y in sampler_params for x in y['energy__']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 degree of freedom -- no more component means or variances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(nu = 1)\n",
    "fit1 = model.sampling(data=data, seed=4838282,\n",
    "                      control=dict(metric=\"unit_e\", stepsize=0.7, \n",
    "                                   max_treedepth=12, adapt_engaged=False))\n",
    "stan_utility.check_all_diagnostics(fit1, 12)\n",
    "\n",
    "sampler_params = fit1.get_sampler_params(inc_warmup=False)\n",
    "stepsizes1 = [sampler_params[n]['stepsize__'][0] \n",
    "              for n in range(4) ]\n",
    "times1 = [stepsizes1[n] * x for n in range(4)\n",
    "          for x in sampler_params[n]['n_leapfrog__'] ]\n",
    "energies1 = [x for y in sampler_params for x in y['energy__']]\n",
    "\n",
    "x0 = fit1.extract(permuted=False)[:,:,0].flatten()\n",
    "iters, x1_mean, x1_se = compute_running_estimator(x0)\n",
    "\n",
    "plot.fill_between(iters, \n",
    "                  [ x1_mean[m] - 2 * x1_se[m] for m in range(len(iters)) ],\n",
    "                  [ x1_mean[m] + 2 * x1_se[m] for m in range(len(iters)) ],\n",
    "                  facecolor=light, color=light)\n",
    "plot.plot(iters, x1_mean, color=dark)\n",
    "plot.plot([iters[0], iters[-1]], [0, 0], color='grey', linestyle='--')\n",
    "\n",
    "plot.gca().set_xlim([0, 4000])\n",
    "plot.gca().set_xlabel(\"Iteration\")\n",
    "plot.gca().set_ylim([-50, 50])\n",
    "plot.gca().set_ylabel(\"Monte Carlo Estimator\")\n",
    "\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot comparison of integration time scalings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plot.subplots(1, 4)\n",
    "    \n",
    "axarr[0].set_title(\"nu = 100\")\n",
    "axarr[0].scatter(energies100, [math.log(x) for x in times100], color=dark, alpha=0.1)\n",
    "axarr[0].set_xlim(0, 50)\n",
    "axarr[0].set_xlabel(\"Energy\")\n",
    "axarr[0].set_ylim([0, 7])\n",
    "axarr[0].set_ylabel(\"Log Integration Time\")\n",
    "\n",
    "axarr[1].set_title(\"nu = 5\")\n",
    "axarr[1].scatter(energies5, [math.log(x) for x in times5], color=dark, alpha=0.1)\n",
    "axarr[1].set_xlim(0, 50)\n",
    "axarr[1].set_xlabel(\"Energy\")\n",
    "axarr[1].set_ylim([0, 7])\n",
    "\n",
    "axarr[2].set_title(\"nu = 2\")\n",
    "axarr[2].scatter(energies2, [math.log(x) for x in times2], color=dark, alpha=0.1)\n",
    "axarr[2].set_xlim(0, 50)\n",
    "axarr[2].set_xlabel(\"Energy\")\n",
    "axarr[2].set_ylim([0, 7])\n",
    "\n",
    "axarr[3].set_title(\"nu = 1\")\n",
    "axarr[3].scatter(energies1, [math.log(x) for x in times1], color=dark, alpha=0.1)\n",
    "axarr[3].set_xlim(0, 50)\n",
    "axarr[3].set_xlabel(\"Energy\")\n",
    "axarr[3].set_ylim([0, 7])\n",
    "\n",
    "plot.subplots_adjust(wspace=0.5)\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "\n",
    "Let's consider an example in the context of Bayesian inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first simulate an observation and save it to a file\n",
    "N = 1\n",
    "simu_data = dict(N = N)\n",
    "\n",
    "simu_model = stan_utility.compile_model('simulate_data.stan')\n",
    "simu = simu_model.sampling(data=simu_data, iter=1, chains=1, seed=4838282,\n",
    "                           algorithm=\"Fixed_param\")\n",
    "\n",
    "data = dict(N = N, y = simu.extract()['y'].flatten())\n",
    "pystan.stan_rdump(data, 'simulation.data.R')\n",
    "\n",
    "# Now we can read that data back in and use Hamiltonian\n",
    "# Monte Carlo to estimate posterior expectation values\n",
    "input_data = pystan.read_rdump('simulation.data.R')\n",
    "\n",
    "model = stan_utility.compile_model('fit_data.stan')\n",
    "fit = model.sampling(data=input_data, seed=4938483)\n",
    "\n",
    "# Check diagnostics\n",
    "stan_utility.check_all_diagnostics(fit)\n",
    "\n",
    "# That doesn't look good.  Let's investigate the divergent\n",
    "# samples in the context of the non-divergent samples to\n",
    "# see what's going on.\n",
    "nondiv_params, div_params = stan_utility.partition_div(fit)\n",
    "\n",
    "plot.scatter(nondiv_params['mu'],\n",
    "             [math.log(x) for x in nondiv_params['sigma']],\n",
    "              color = mid_highlight, alpha=0.05)\n",
    "plot.scatter(div_params['mu'],\n",
    "             [math.log(x) for x in div_params['sigma']],\n",
    "              color = green, alpha=0.5)\n",
    "\n",
    "plot.gca().set_xlabel(\"mu\")\n",
    "plot.gca().set_ylabel(\"sigma\")\n",
    "plot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36ws",
   "language": "python",
   "name": "p36ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
