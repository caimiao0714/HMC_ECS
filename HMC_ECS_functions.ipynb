{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import halfcauchy\n",
    "from scipy.stats import invgamma\n",
    "from scipy.linalg import sqrtm\n",
    "import scipy.optimize\n",
    "import random\n",
    "import numpy.random as npr\n",
    "import copy\n",
    "import time\n",
    "import scipy.stats as sps\n",
    "#import mpmath as mp\n",
    "import scipy.special\n",
    "import os\n",
    "import numdifftools as nd\n",
    "from scipy.special import polygamma, gammaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1523)\n",
    "#precision = 150\n",
    "#mp.mp.prec += precision\n",
    "def loglike_ind(y,x,theta):\n",
    "    \n",
    "    \"\"\"this function evaluate the individual log likelihood at individual level\n",
    "     input is whole data set\n",
    "    \"\"\"\n",
    "    \n",
    "    npar = np.shape(x)[1]\n",
    "    tmp = x.dot(theta[:npar])\n",
    "    if np.any(tmp > 700):\n",
    "        tmp[np.where(tmp>700)]=700\n",
    "    \n",
    "    out = (y.T)*tmp - np.log1p(np.exp(tmp))\n",
    "    \n",
    "    if(np.isnan(out).any()==True):\n",
    "        out[np.where(np.isnan(out))] = np.log(1e-100)\n",
    "    return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike_all(y,x,theta):\n",
    "    \"\"\" \n",
    "    loglikelihood of whole data set\n",
    "    \"\"\"\n",
    "    npar = np.shape(x)[1]\n",
    "    ll_ind = loglike_ind(y,x,theta[:npar])\n",
    "    out = np.sum(ll_ind)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessianll(x,theta):\n",
    "    \"\"\"function that evaluate the second derivative of the likelihood at a value of the data , for 1 data point\"\"\"\n",
    "    \n",
    "    npar = len(x) # number of real parameter\n",
    "    out = np.zeros([len(theta),len(theta)])\n",
    "    out[:npar,:npar] = -np.exp(np.dot(x,theta[:npar]))/(1+np.exp(np.dot(x,theta[:npar])))**2*np.outer(x,x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessianll2(x,theta):\n",
    "    \"\"\"function that evaluate the second derivative of the (individual) likelihood at a value of the data \"\"\"\n",
    "    npar = np.int(np.shape(x)[1])\n",
    "    \n",
    "    tmp = -1/(np.exp(0.5*np.dot(x,theta[:npar]))+np.exp(-0.5*np.dot(x,theta[:npar])))**2\n",
    "    out = np.zeros([len(x),len(theta),len(theta)])\n",
    "    out[:,:npar,:npar] = np.array(map(np.multiply,x[:,:,None]*x[:,None,:],tmp))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumHessian(x,theta):\n",
    "    n = len(x)\n",
    "    H = 0\n",
    "    for i in range(0,n):\n",
    "        H = H + hessianll(x[i],theta)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessianPrior(theta,family,par1,par2):\n",
    "    \"\"\"function that evaluate the second derivative of the prior at a value of the data \"\"\"\n",
    "\n",
    "    if(family== 'gaussian'):\n",
    "        out = -np.linalg.inv(par2)\n",
    "        \n",
    "    else:\n",
    "        print (\"prior not defined !\")\n",
    "        out = np.nan\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devll_ind(y,x,theta):\n",
    "    \n",
    "    \"\"\"\n",
    "    function that evaluate the first derivative of the log likelihood at a value of the data\n",
    "    for individual\n",
    "    \"\"\"\n",
    "    \n",
    "    #npar = np.shape(data)[1]-1L\n",
    "    npar = len(x)\n",
    "    tmp = np.dot(x,theta[:npar])\n",
    "    if (tmp < -700):\n",
    "       tmp=-700\n",
    "    out = np.zeros(len(theta))\n",
    "    out[:npar] = y*x - x*1/(1+np.exp(-tmp))\n",
    "    return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devll(y,x,theta):\n",
    "    \"\"\" for a set of observations\n",
    "    \"\"\"\n",
    "    npar = np.shape(x)[1] #number of 'real' parameters- betas\n",
    "    tmp = np.dot(x,theta[:npar])\n",
    "    if (np.any(tmp < -700)==True):\n",
    "       tmp[np.where(tmp<-700)]=-700\n",
    "    tmp = 1/(1+np.exp(-tmp)) \n",
    "    out = np.zeros([len(y),npar])\n",
    "    out[:,:npar] = np.multiply(x.T,y-tmp).T   \n",
    "    #out = y*x - np.multiply(x.T,tmp).T\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumDev(y,x,theta):\n",
    "    n = len(y)\n",
    "    D = 0\n",
    "    for i in range(0,n):\n",
    "        D = D+   devll_ind(y[i],x[i],theta)  \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprior(theta,family,par1,par2):\n",
    "    \"\"\"\n",
    "    log prior \n",
    "    \n",
    "    for a gaussian prior, par1 is mean, par2 is covariance matrix\n",
    "    \"\"\"\n",
    "    if family =='gaussian':\n",
    "        out = -0.5*np.dot((theta-par1),np.linalg.solve(par2,(theta-par1)))\n",
    "        #out = np.log(max(1e-300,multivariate_normal.pdf(theta,par1,par2)))\n",
    "    else:\n",
    "        print ('prior not defined')\n",
    "        out = np.nan\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradPrior(theta,prior,npar,priorPar1 = 0, priorPar2  =0):\n",
    "    \n",
    "    if prior =='gaussian':\n",
    "        gradPrior = - np.linalg.solve(priorPar2,theta-priorPar1)\n",
    "    else:\n",
    "        print ('prior not defined')\n",
    "        gradPrior = np.nan\n",
    "    return gradPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradU(y,x,theta,prior='uniform',priorPar1=0,priorPar2=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    function that evaluate the gradient of minus the log posterior \n",
    "    \"\"\"\n",
    "    npar = np.shape(x)[1]\n",
    "    const = 1/(1+np.exp(-np.dot(x,theta[:npar])))\n",
    "    dev_ind = y.reshape(-1,1)*x - const.reshape(-1,1)*x\n",
    "    gradll= np.zeros(len(theta))\n",
    "    gradll[:npar] = -np.sum(dev_ind,axis =0) #minus gradient of log likelihood\n",
    "    gPrior = gradPrior(theta,prior,npar,priorPar1,priorPar2)\n",
    "    out = gradll  - gPrior\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential(y,x,theta,par1,par2,family):\n",
    "    \"\"\" potential energy\"\"\"\n",
    "    U = -(loglike_all(y,x,theta)+dprior(theta,family,par1,par2))\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kinetic(p,M):\n",
    "    # technically just minus the log of multivariate normal density with mean 0 and covariance M, without the normalizing constant\n",
    "    # may be numpy library is faster but just use the formular first\n",
    "   \n",
    "    K = 0.5*p.dot(np.linalg.solve(M,p))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-ba7015e9135c>, line 165)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-ba7015e9135c>\"\u001b[1;36m, line \u001b[1;32m165\u001b[0m\n\u001b[1;33m    except Warning, w:\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def hmc(y,x, theta,burnin,samples,eps,trajLength,maxSteps,M,priorArgs,adaptArgs,logFile,saveTempOutput=False):\n",
    "    \"\"\" IMPLEMENTATION OF HMC WITH ADAPTIVE WARMUP\n",
    "        M to be updated using the output from the previous iterations\n",
    "        eps to be updated continously during burnin\n",
    "        \n",
    "    \"\"\"\n",
    "    # eps is stepsize (starting value, to be update if burnin>0)\n",
    "    # L is number of steps (fix)\n",
    "    # M is covariance matrix of p (to be update if burnin > 0)\n",
    "    \n",
    "    # burnin = 0 implies no update at all\n",
    "    \n",
    "    #n = len(data)\n",
    "    niter = burnin + samples\n",
    "    npar = len(theta)\n",
    "    nbetas = np.shape(x)[1]\n",
    "    theta_keep = np.zeros([niter,npar])\n",
    "    theta_propose = np.zeros([niter,npar])\n",
    "    acc_rate = np.zeros(niter)\n",
    "    L_keep = np.zeros(niter)\n",
    "    L = int(trajLength[0]/eps)\n",
    "    timePerIter = np.zeros(niter)\n",
    "    Hdiff = np.zeros(niter)\n",
    "    # arguments for prior\n",
    "    pfamily = priorArgs['family']\n",
    "    priorPar1 = priorArgs['par1']\n",
    "    priorPar2 = priorArgs['par2']\n",
    "    \n",
    "    meanp = np.zeros(len(theta))\n",
    "    #-------------------------------#\n",
    "    updateFreq = adaptArgs['updateFreq']\n",
    "    alpha = adaptArgs['alpha'] #desired acceptance rate\n",
    "    gamma =adaptArgs['gamma']\n",
    "    kappa = adaptArgs['kappa']\n",
    "    updateM = adaptArgs['updateM']\n",
    "    t0 = adaptArgs['t0']\n",
    "    Hbar = 0 #Hbar is a sumstat ~ different between the desired acceptance rate and the mean acceptance rate upto time t\n",
    "    mu = np.log(10*eps)\n",
    "    logEps = np.log(eps)\n",
    "    logEpsBar = 0\n",
    "    #-----------------------------------#\n",
    "    #\n",
    "    if(adaptArgs['adapt']==True and burnin>0):\n",
    "        eps_keep =np.zeros(niter)\n",
    "        eps_keep[0] = eps\n",
    "        diagM = adaptArgs['diagM']\n",
    "        phaseStartPt = adaptArgs['phaseStartPt']\n",
    "        if(len(phaseStartPt) != len(trajLength)):\n",
    "            print('phaseEndPt must have same length as trajLength')\n",
    "            \n",
    "        phase = 0\n",
    "    else:\n",
    "        eps_keep = eps\n",
    "    #-------------------------------#\n",
    "    try:\n",
    "        for i in range(0,niter):\n",
    "            progress = i*100/niter\n",
    "            if np.mod(progress,5)==0:\n",
    "                print(str(progress)+ \"% \",end= \"\")\n",
    "            if (np.mod(progress,10)==0 and i>0):\n",
    "                msg = str(progress) + \"% ; nsteps now is: \" + str(L) + \"; mean acc is: \" + str(np.mean(acc_rate[:i]))\n",
    "                print(msg)\n",
    "                lf = open(logFile,\"a\")\n",
    "                lf.write(msg+ '\\n')\n",
    "                lf.close()\n",
    "                if(saveTempOutput):\n",
    "                    part = int(progress*0.1)\n",
    "                    temp = {'par':theta_keep[:i],'eps':eps_keep,'M':M}\n",
    "                    np.save('output/temp'+ str(part) + '.npy',temp)\n",
    "                        \n",
    "            startT = time.time() \n",
    "            \n",
    "               \n",
    "            p = np.random.multivariate_normal(meanp,M,1)[0]\n",
    "            thetacurrent = theta\n",
    "            Hcurrent = -(loglike_all(y,x,theta[:nbetas])+dprior(theta,pfamily,priorPar1,priorPar2))+ kinetic(p,M)\n",
    "            \n",
    "            L_keep[i] = L\n",
    "            # move p by half a step\n",
    "            p = p-0.5*eps*gradU(y,x,theta,pfamily,priorPar1,priorPar2)\n",
    "            for s in range(0,L):\n",
    "                # move position\n",
    "                theta = theta+ eps*np.linalg.solve(M,p)\n",
    "                # move momentum\n",
    "                if s<(L-1):\n",
    "                    p = p - eps*gradU(y,x,theta,pfamily,priorPar1,priorPar2)\n",
    "                else:\n",
    "                    p = p - 0.5*eps*gradU(y,x,theta,pfamily,priorPar1,priorPar2)\n",
    "                \n",
    "            # negate p\n",
    "            p = -p\n",
    "            theta_propose[i] = theta\n",
    "            H = -(loglike_all(y,x,theta[:nbetas])+dprior(theta,pfamily,priorPar1,priorPar2))+ kinetic(p,M)\n",
    "        \n",
    "            \n",
    "            reject = False\n",
    "            Hdiff[i] = Hcurrent - H\n",
    "            accrate = np.exp(min([0,(Hcurrent-H)]))#\n",
    "            reject = (np.random.uniform(0,1,1)> accrate)\n",
    "            if reject==True:\n",
    "                theta = thetacurrent\n",
    "                H = Hcurrent\n",
    "            stopT = time.time()\n",
    "            timePerIter[i] = stopT- startT\n",
    "            \n",
    "            #------------------------------------------------#\n",
    "            # adjust eps and M if burnin > 0\n",
    "            # don't evaluate the time getting new eps for adaptive tunning as it's small\n",
    "            if(burnin >0):\n",
    "                t = i+ 1\n",
    "                if(adaptArgs['adapt']==True):\n",
    "                    if(updateM and np.mod(i+1,updateFreq)==0 ):\n",
    "                        startT = time.time()\n",
    "                        if(diagM ==True):\n",
    "                            var_theta = np.var(theta_keep[int(i/2):(i+1),:],axis = 0) #take half the iteration as the first iters might not be informative\n",
    "                            M= np.diag(1/var_theta)\n",
    "                        else:\n",
    "                            \n",
    "                            thetaRef = np.mean(theta_keep[int(0.5*i):i,:],axis =0)\n",
    "                            \n",
    "                            Hprior = hessianPrior(thetaRef,pfamily,priorPar1,priorPar2)\n",
    "                            M = -sumHessian(x, thetaRef) - Hprior\n",
    "                        stopT = time.time()\n",
    "                        timePerIter[i] = timePerIter[i] + stopT- startT  \n",
    "                    \n",
    "                    if(i< burnin):\n",
    "                        Hbar = (1-1/(t+t0))*Hbar + 1/(t+t0)*(alpha-accrate)\n",
    "                        logEps = mu - np.sqrt(t)/gamma*Hbar\n",
    "                        logEpsBar = t**(-kappa)*logEps + (1-t**(-kappa))*logEpsBar\n",
    "                                                                                                        \n",
    "                        if(phase < len(phaseStartPt)):\n",
    "                            if((i+1)==phaseStartPt[phase]):\n",
    "                                currentTrajLength = trajLength[phase]\n",
    "                                phase +=1 #next phase is phase 1\n",
    "                            # reset\n",
    "                            #if(phase < len(phaseStartPt)):\n",
    "                            #    mu = np.log(10*eps)\n",
    "                            #    logEps = np.log(eps)\n",
    "                            #    logEpsBar = 0\n",
    "                            #    Hbar = 0 \n",
    "                        eps = np.min([adaptArgs['maxEps'],np.exp(logEps),currentTrajLength])\n",
    "                        eps_keep[t] = eps\n",
    "                        L = min(maxSteps,int(round(currentTrajLength/eps,0)))   \n",
    "                        if (L==0):\n",
    "                            print('number of steps reaches 0!')\n",
    "                            L +=1     \n",
    "                        if(t==burnin) :\n",
    "                            # t == burnin\n",
    "                            eps = np.min([np.exp(logEpsBar),adaptArgs['maxEps'],currentTrajLength])\n",
    "                            eps_keep[t:] = eps\n",
    "                            L = min(maxSteps,int(round(trajLength[-1]/eps,0)))\n",
    "                            L_fix = max(1,L)\n",
    "                    \n",
    "                    else:\n",
    "                        L = L_fix\n",
    "                else:\n",
    "                    if t < burnin :\n",
    "                        L = int(round(trajLength[0]/eps,0))\n",
    "                    else:\n",
    "                        L = int(round(trajLength[1]/eps,0))\n",
    "                                                                \n",
    "                \n",
    "            theta_keep[i]= theta\n",
    "            acc_rate[i] = accrate\n",
    "    except Warning,w:\n",
    "        print (str(w))\n",
    "    except TypeError,e:\n",
    "        print('type error' + str(e))\n",
    "    except ValueError,e:\n",
    "        print('value error'+ str(e))\n",
    "    except IndexError,e:\n",
    "       print('Index error'+ str(e))\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print('Bye')\n",
    "    lf = open(logFile,\"a\")\n",
    "    lf.write('Run completed successfully')\n",
    "    lf.close()\n",
    "    \n",
    "    finalpar = {'theta':theta_keep}\n",
    "    currentSet = {'theta':theta,'iter':i}\n",
    "    return {'par':finalpar,'acc': acc_rate,'eps':eps_keep,'nsteps':L_keep,'M':M,'Hbar':Hbar,'runTime':timePerIter,\n",
    "    'Hdiff': Hdiff,'current':currentSet,'proposal':theta_propose,'args':adaptArgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2_7",
   "language": "python",
   "name": "py2_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
